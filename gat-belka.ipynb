{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":67356,"databundleVersionId":8006601,"sourceType":"competition"},{"sourceId":8519891,"sourceType":"datasetVersion","datasetId":4784530}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-19T08:50:11.124284Z","iopub.execute_input":"2024-06-19T08:50:11.124684Z","iopub.status.idle":"2024-06-19T08:50:11.598641Z","shell.execute_reply.started":"2024-06-19T08:50:11.124646Z","shell.execute_reply":"2024-06-19T08:50:11.597981Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Launch Kaggle TPU session\nprint('Session Start!')","metadata":{"execution":{"iopub.status.busy":"2024-06-19T08:50:11.599793Z","iopub.execute_input":"2024-06-19T08:50:11.600099Z","iopub.status.idle":"2024-06-19T08:50:11.604621Z","shell.execute_reply.started":"2024-06-19T08:50:11.600073Z","shell.execute_reply":"2024-06-19T08:50:11.603860Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Session Start!\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\nimport threading\nimport tensorflow as tf\n\n# Function to keep the TPU active\ndef keep_tpu_active():\n    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(resolver)\n    tf.tpu.experimental.initialize_tpu_system(resolver)\n    strategy = tf.distribute.TPUStrategy(resolver)\n    \n    while True:\n        with strategy.scope():\n            # Minimal operation to keep TPU active\n            dummy_tensor = tf.constant(1)\n            tf.print(dummy_tensor)\n        time.sleep(600)  # Wait for 10 minutes before the next operation\n\n# Start the keep_tpu_active function in a background thread\ntpu_thread = threading.Thread(target=keep_tpu_active)\ntpu_thread.daemon = True\ntpu_thread.start()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torch_geometric\n!pip install indexed_bzip2\n!pip install rdkit","metadata":{"execution":{"iopub.status.busy":"2024-06-19T08:50:11.605426Z","iopub.execute_input":"2024-06-19T08:50:11.605666Z","iopub.status.idle":"2024-06-19T08:50:21.709197Z","shell.execute_reply.started":"2024-06-19T08:50:11.605641Z","shell.execute_reply":"2024-06-19T08:50:21.708304Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/site-packages (2.5.3)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/site-packages (from torch_geometric) (5.9.8)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch_geometric) (2024.3.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from torch_geometric) (2.31.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/site-packages (from torch_geometric) (3.9.5)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from torch_geometric) (1.13.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch_geometric) (3.1.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from torch_geometric) (4.66.2)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/site-packages (from torch_geometric) (1.4.2)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/site-packages (from torch_geometric) (3.1.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->torch_geometric) (23.2.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->torch_geometric) (4.0.3)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp->torch_geometric) (6.0.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch_geometric) (2.1.5)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->torch_geometric) (3.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->torch_geometric) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->torch_geometric) (2.2.1)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->torch_geometric) (2024.2.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (3.4.0)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (1.4.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nRequirement already satisfied: indexed_bzip2 in /usr/local/lib/python3.10/site-packages (1.6.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nRequirement already satisfied: rdkit in /usr/local/lib/python3.10/site-packages (2023.9.6)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/site-packages (from rdkit) (10.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from rdkit) (1.26.4)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.loader import DataLoader as PyGDataLoader\nfrom torch.nn import Sequential, Linear, ReLU\nfrom torch_geometric.nn import GATConv\nfrom torch_geometric.nn import global_max_pool as gmp\nimport indexed_bzip2 as ibz2\nimport os\nimport pickle\nimport rdkit\nfrom rdkit import Chem\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\n#from torch_scatter import scatter\nfrom multiprocessing import Pool\nfrom tqdm import tqdm\nimport gc\nprint('import DONE!')","metadata":{"execution":{"iopub.status.busy":"2024-06-19T08:50:21.711338Z","iopub.execute_input":"2024-06-19T08:50:21.711898Z","iopub.status.idle":"2024-06-19T08:50:26.129945Z","shell.execute_reply.started":"2024-06-19T08:50:21.711865Z","shell.execute_reply":"2024-06-19T08:50:26.129051Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n","output_type":"stream"},{"name":"stdout","text":"import DONE!\n","output_type":"stream"}]},{"cell_type":"code","source":"#class GATNet(torch.nn.Module):\n#    def __init__(self, num_features=9, n_output=3,n_filters=32, embed_dim=128, output_dim=1, dropout=0.5):\n#        super(GATNet, self).__init__()\n\n        # GATConv\n#        self.gcn1 = GATConv(num_features, num_features , heads=10, dropout=dropout)\n#        self.gcn2 = GATConv(num_features * 10, output_dim, dropout=dropout)\n#        self.fc_g1 = nn.Linear(output_dim, output_dim)\n\n\n #       self.fc1 = nn.Linear(output_dim, 64)\n #       self.fc2 = nn.Linear(64, 32)\n #       self.out = nn.Linear(32, n_output)\n\n        # relu and dropout\n #       self.relu = nn.ReLU()\n #       self.dropout = nn.Dropout(dropout)\n\n #   def forward(self, data):\n #       x, edge_index, batch = data.x.float(), data.edge_index, data.batch\n\n #      x = F.dropout(x, p=0.2, training=self.training)\n #       x = F.elu(self.gcn1(x, edge_index))\n #       x = F.dropout(x, p=0.2, training=self.training)\n #       x = self.gcn2(x, edge_index)\n #       x = self.relu(x)\n #       x = gmp(x, batch)          \n #       x = self.fc_g1(x)\n #       x = self.relu(x)#\n\n        # dense layers\n #      xc = self.fc1(x)\n #       xc = self.relu(xc)\n #       xc = self.dropout(xc)\n #       xc = self.fc2(xc)\n #       xc = self.relu(xc)\n #       xc = self.dropout(xc)\n #       out = self.out(xc)\n #       return out\n    \n#model = GATNet()\n#optimizer = optim.Adam(model.parameters(), lr=0.01)\n\n#def custom_loss(output, target):\n #   loss = 0\n #   for i in range(3):  \n #       loss += F.binary_cross_entropy_with_logits(output[0][i], target[i].float())\n #   return loss / 3  \n\n\n# Training\n#def train_model(training_set):\n  #  model.train()\n #   for data in training_set:\n  #      optimizer.zero_grad()\n #       output = model(data)\n        #print(output)\n        #print(data.y)\n        #print(output[0][2].float(), data.y[0].float())\n  #      loss = custom_loss(output, data.y)#F.binary_cross_entropy_with_logits(output, data.y.view(-1, 3))\n  #      loss.backward()\n  #      optimizer.step()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-19T08:50:26.131049Z","iopub.execute_input":"2024-06-19T08:50:26.131489Z","iopub.status.idle":"2024-06-19T08:50:26.136706Z","shell.execute_reply.started":"2024-06-19T08:50:26.131459Z","shell.execute_reply":"2024-06-19T08:50:26.135859Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load first 30m Train_graph\ndef load_compressed_ibz2_pickle(file):\n    with ibz2.open(file, parallelization=os.cpu_count()) as f:\n        data = pickle.load(f)\n    return data\ngdf_train = load_compressed_ibz2_pickle(\n    '/kaggle/input/leash-bio-processed-dataset/train-replace-c-30m.graph.pickle.b2z'\n)\nprint('train_graph Loaded!')\n\n# Load Train_bind\ntrainbind_data = np.load('/kaggle/input/leash-bio-processed-dataset/train.bind.npz')\ntrain_bind = trainbind_data['bind']\ntrainbind_data.close()\nprint('train_bind Loaded!')\n\nprint(len(gdf_train),len(train_bind))\nprint('DONE!')","metadata":{"execution":{"iopub.status.busy":"2024-06-19T08:50:26.137706Z","iopub.execute_input":"2024-06-19T08:50:26.137952Z","iopub.status.idle":"2024-06-19T08:55:23.159665Z","shell.execute_reply.started":"2024-06-19T08:50:26.137927Z","shell.execute_reply":"2024-06-19T08:55:23.158914Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"train_graph Loaded!\ntrain_bind Loaded!\n30000000 98415610\nDONE!\n","output_type":"stream"}]},{"cell_type":"code","source":"#Run when loading full training dataset\n#gdf_train2 = load_compressed_ibz2_pickle(\n#    '/kaggle/input/leash-bio-processed-dataset/train-replace-c-30m.graph.pickle.01.b2z'\n#)\n#print('train_graph Loaded!')\n#print(len(gdf_train2))\n\n#gdf_train3 = load_compressed_ibz2_pickle(\n#    '/kaggle/input/leash-bio-processed-dataset/train-replace-c-30m.graph.pickle.02.b2z'\n#)\n#print('train_graph Loaded!')\n#print(len(gdf_train3))","metadata":{"execution":{"iopub.status.busy":"2024-06-19T08:55:23.160636Z","iopub.execute_input":"2024-06-19T08:55:23.160896Z","iopub.status.idle":"2024-06-19T08:55:23.164306Z","shell.execute_reply.started":"2024-06-19T08:55:23.160869Z","shell.execute_reply":"2024-06-19T08:55:23.163713Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#merge train_graph datasets\ngdf_train_concat =  gdf_train #+ gdf_train2 + gdf_train3  #add train2 and train3 when loading full training dataset\nprint(\"DONE\",len(gdf_train_concat))","metadata":{"execution":{"iopub.status.busy":"2024-06-19T08:55:23.165132Z","iopub.execute_input":"2024-06-19T08:55:23.165575Z","iopub.status.idle":"2024-06-19T08:55:23.176619Z","shell.execute_reply.started":"2024-06-19T08:55:23.165546Z","shell.execute_reply":"2024-06-19T08:55:23.175993Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"DONE 30000000\n","output_type":"stream"}]},{"cell_type":"code","source":"zipped = list(zip(gdf_train_concat,train_bind[:30000000]))\n\npos_class = [x for x in zipped if sum(x[1]) > 0]\nneg_class = [x for x in zipped if sum(x[1]) == 0]\nprint(len(pos_class),len(neg_class))\nprint(\"DONE!\")","metadata":{"execution":{"iopub.status.busy":"2024-06-19T08:55:23.177441Z","iopub.execute_input":"2024-06-19T08:55:23.177699Z","iopub.status.idle":"2024-06-19T08:58:26.492425Z","shell.execute_reply.started":"2024-06-19T08:55:23.177674Z","shell.execute_reply":"2024-06-19T08:58:26.491762Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"822875 29177125\nDONE!\n","output_type":"stream"}]},{"cell_type":"code","source":"#skip when training for submission\nimport random\nrandom.shuffle(pos_class)\nrandom.shuffle(neg_class)\n\ntrain_sample = pos_class[:50000] + neg_class[:50000]\ntrain_graph_sample = []\ntrain_bind_sample = []\n\nrandom.shuffle(train_sample)\n\nfor i in train_sample:\n    train_graph_sample.append(i[0])\n    train_bind_sample.append(i[1])\n    \n#test_sample = pos_class[50000:80000] + neg_class[50000:80000]\n#test_graph_sample = []\n#test_bind_sample = []\n#for i in test_sample:\n#    test_graph_sample.append(i[0])\n#    test_bind_sample.append(i[1])\n    \nprint('length of train split: ',len(train_graph_sample), len(train_bind_sample))\n#print('length of test split: ',len(test_graph_sample), len(test_bind_sample))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-19T08:58:26.494952Z","iopub.execute_input":"2024-06-19T08:58:26.495353Z","iopub.status.idle":"2024-06-19T08:58:52.925126Z","shell.execute_reply.started":"2024-06-19T08:58:26.495324Z","shell.execute_reply":"2024-06-19T08:58:52.924434Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"length of train split:  100000 100000\n","output_type":"stream"}]},{"cell_type":"code","source":"#check train_bind \ntrain_bind_sample[:5]","metadata":{"execution":{"iopub.status.busy":"2024-06-19T08:58:52.926008Z","iopub.execute_input":"2024-06-19T08:58:52.926265Z","iopub.status.idle":"2024-06-19T08:58:52.933867Z","shell.execute_reply.started":"2024-06-19T08:58:52.926240Z","shell.execute_reply":"2024-06-19T08:58:52.933255Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[array([0, 0, 0], dtype=uint8),\n array([0, 0, 0], dtype=uint8),\n array([0, 0, 1], dtype=uint8),\n array([0, 0, 0], dtype=uint8),\n array([0, 0, 1], dtype=uint8)]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Helper: convert graph to pyg list\ndef to_pyg_list(graph):\n    L = len(graph)\n    for i in tqdm(range(L)):\n        N, edge, node_feature, edge_feature = graph[i]\n        graph[i] = Data(\n            idx=i,\n            edge_index=torch.from_numpy(edge.T).int(),\n            x=torch.from_numpy(node_feature).byte(),\n            edge_attr=torch.from_numpy(edge_feature).byte(),\n            y=torch.tensor(train_bind_sample[i])\n        )\n    return graph\n\n#Helper for test_split\ndef to_pyg_list_test(graph):\n    L = len(graph)\n    for i in tqdm(range(L)):\n        N, edge, node_feature, edge_feature = graph[i]\n        graph[i] = Data(\n            idx=i,\n            edge_index=torch.from_numpy(edge.T).int(),\n            x=torch.from_numpy(node_feature).byte(),\n            edge_attr=torch.from_numpy(edge_feature).byte()\n        )\n    return graph\n\n# Converted test_graph, with label\ndef to_pyg_list_tests_wlabel(graph):\n    L = len(graph)\n    for i in tqdm(range(L)):\n        N, edge, node_feature, edge_feature = graph[i]\n        graph[i] = Data(\n            idx=i,\n            edge_index=torch.from_numpy(edge.T).int(),\n            x=torch.from_numpy(node_feature).byte(),\n            edge_attr=torch.from_numpy(edge_feature).byte(),\n            y=torch.tensor(test_bind_sample[i])\n        )\n    return graph\nprint('DONE!')","metadata":{"execution":{"iopub.status.busy":"2024-06-19T08:58:52.934695Z","iopub.execute_input":"2024-06-19T08:58:52.934917Z","iopub.status.idle":"2024-06-19T08:58:52.969700Z","shell.execute_reply.started":"2024-06-19T08:58:52.934894Z","shell.execute_reply":"2024-06-19T08:58:52.969081Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"DONE!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Converted train-graph, with label\ntrain_graph = to_pyg_list(train_graph_sample)\n#test_graph_wlabel = to_pyg_list_tests_wlabel(test_graph_sample)\nprint(len(train_graph))\ntrain_graph[:5]","metadata":{"execution":{"iopub.status.busy":"2024-06-19T08:58:52.970515Z","iopub.execute_input":"2024-06-19T08:58:52.970757Z","iopub.status.idle":"2024-06-19T08:59:21.981617Z","shell.execute_reply.started":"2024-06-19T08:58:52.970733Z","shell.execute_reply":"2024-06-19T08:59:21.980956Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"100%|██████████| 100000/100000 [00:28<00:00, 3449.13it/s]","output_type":"stream"},{"name":"stdout","text":"100000\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"[Data(x=[40, 9], edge_index=[2, 86], edge_attr=[86, 1], y=[3], idx=0),\n Data(x=[39, 9], edge_index=[2, 82], edge_attr=[82, 1], y=[3], idx=1),\n Data(x=[45, 9], edge_index=[2, 104], edge_attr=[104, 1], y=[3], idx=2),\n Data(x=[45, 9], edge_index=[2, 100], edge_attr=[100, 1], y=[3], idx=3),\n Data(x=[43, 9], edge_index=[2, 96], edge_attr=[96, 1], y=[3], idx=4)]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GATNet(torch.nn.Module):\n    def __init__(self, num_features=9, n_output=3, output_dim=32, dropout=0.5):\n        super(GATNet, self).__init__()\n\n        self.gcn1 = GATConv(num_features, num_features, heads=10, dropout=dropout)\n        self.gcn2 = GATConv(num_features * 10, output_dim, dropout=dropout)\n        self.fc_g1 = nn.Linear(output_dim, output_dim)\n\n        # add batch normalization\n        self.bn1 = nn.BatchNorm1d(output_dim)\n\n        self.fc1 = nn.Linear(output_dim, 64)\n        self.fc2 = nn.Linear(64, 32)\n        self.out = nn.Linear(32, n_output)\n\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, data):\n        x, edge_index, batch = data.x.float(), data.edge_index, data.batch\n\n        x = F.dropout(x, p=0.2, training=self.training)\n        x = F.elu(self.gcn1(x, edge_index))\n        x = F.dropout(x, p=0.2, training=self.training)\n        x = self.gcn2(x, edge_index)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = gmp(x, batch)          \n        x = self.fc_g1(x)\n        x = self.relu(x)\n\n        # Dense layers\n        xc = self.fc1(x)\n        xc = self.relu(xc)\n        xc = self.dropout(xc)\n        xc = self.fc2(xc)\n        xc = self.relu(xc)\n        xc = self.dropout(xc)\n        out = self.out(xc)\n        return out\n\nmodel = GATNet()\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  \nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n\ndef custom_loss(output, target):\n    output = output.view(-1)\n    target = target.view(-1)\n    return F.binary_cross_entropy_with_logits(output, target.float())\n\ndef train_model(training_set, batch_size=50000, epochs=8):\n    model.train()\n    dataloader = DataLoader(training_set, batch_size=batch_size, shuffle=True)\n    for epoch in range(epochs):\n        total_loss = 0\n        for data in dataloader:\n            optimizer.zero_grad()\n            output = model(data)\n            loss = custom_loss(output, data.y)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping\n            optimizer.step()\n            total_loss += loss.item()\n            \n        # update learning rate\n        scheduler.step()  \n        print(f'Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}')","metadata":{"execution":{"iopub.status.busy":"2024-06-19T08:59:21.982547Z","iopub.execute_input":"2024-06-19T08:59:21.982815Z","iopub.status.idle":"2024-06-19T08:59:22.074300Z","shell.execute_reply.started":"2024-06-19T08:59:21.982779Z","shell.execute_reply":"2024-06-19T08:59:22.073553Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# For Debug\ntraining_set = train_graph#[:10000]#[Data(idx=-1, edge_index=None, x=torch.rand(5, 20), edge_attr=None, y=torch.tensor([0, 0, 1])) for _ in range(10)]\n\n# Train with the training_set\ntrain_model(training_set)\nprint('training DONE!')","metadata":{"execution":{"iopub.status.busy":"2024-06-19T08:59:22.075250Z","iopub.execute_input":"2024-06-19T08:59:22.075527Z","iopub.status.idle":"2024-06-19T09:03:02.462089Z","shell.execute_reply.started":"2024-06-19T08:59:22.075484Z","shell.execute_reply":"2024-06-19T09:03:02.461181Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n  warnings.warn(out)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.6619117558002472\nEpoch 2, Loss: 0.6481131911277771\nEpoch 3, Loss: 0.632734090089798\nEpoch 4, Loss: 0.6156827807426453\nEpoch 5, Loss: 0.5960244834423065\nEpoch 6, Loss: 0.5736572742462158\nEpoch 7, Loss: 0.5494276285171509\nEpoch 8, Loss: 0.5250816941261292\ntraining DONE!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Prediction function\ndef predict_label(data):\n    model.eval()\n    output = model(data)\n    labels = torch.sigmoid(output).detach().numpy()\n    #predicted_label = 0 if np.mean(labels)<0.1 else 1\n    return labels#predicted_label","metadata":{"execution":{"iopub.status.busy":"2024-06-19T09:03:02.463236Z","iopub.execute_input":"2024-06-19T09:03:02.463556Z","iopub.status.idle":"2024-06-19T09:03:02.467975Z","shell.execute_reply.started":"2024-06-19T09:03:02.463525Z","shell.execute_reply":"2024-06-19T09:03:02.467144Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Threshold\ntest_sample = pos_class[75000:80000] + neg_class[75000:80000]\ntest_graph_sample = []\ntest_bind_sample = []\n\nrandom.shuffle(train_sample)\n\nfor i in test_sample:\n    test_graph_sample.append(i[0])\n    test_bind_sample.append(i[1])\n    \nprint('length of test split: ',len(test_graph_sample), len(test_bind_sample))\n\n#Convert testset to graph object\ndef to_pyg_list_test(graph):\n    L = len(graph)\n    for i in tqdm(range(L)):\n        N, edge, node_feature, edge_feature = graph[i]\n        graph[i] = Data(\n            idx=i,\n            edge_index=torch.from_numpy(edge.T).int(),\n            x=torch.from_numpy(node_feature).byte(),\n            edge_attr=torch.from_numpy(edge_feature).byte(),\n            y=torch.tensor(test_bind_sample[i])\n        )\n    return graph\n\n#test_sample = pos_class[-5:]+neg_class[-5:]\ntest_graph_converted = to_pyg_list_test(test_graph_sample)\n\nprint('DONE!')\ntest_graph_converted[:5]","metadata":{"execution":{"iopub.status.busy":"2024-06-19T09:03:02.469006Z","iopub.execute_input":"2024-06-19T09:03:02.469267Z","iopub.status.idle":"2024-06-19T09:03:21.246495Z","shell.execute_reply.started":"2024-06-19T09:03:02.469240Z","shell.execute_reply":"2024-06-19T09:03:21.245765Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"length of test split:  100000 100000\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100000/100000 [00:18<00:00, 5386.29it/s]","output_type":"stream"},{"name":"stdout","text":"DONE!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"[Data(x=[42, 9], edge_index=[2, 92], edge_attr=[92, 1], y=[3], idx=0),\n Data(x=[39, 9], edge_index=[2, 84], edge_attr=[84, 1], y=[3], idx=1),\n Data(x=[42, 9], edge_index=[2, 92], edge_attr=[92, 1], y=[3], idx=2),\n Data(x=[40, 9], edge_index=[2, 90], edge_attr=[90, 1], y=[3], idx=3),\n Data(x=[48, 9], edge_index=[2, 106], edge_attr=[106, 1], y=[3], idx=4)]"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GATConv, global_mean_pool as gmp\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm import tqdm\n\ndef evaluate_model(test_set):\n    model.eval()\n    all_labels = []\n    all_preds = []\n    \n    with torch.no_grad():\n        for data in test_set:\n            output = model(data)\n            output_sigmoid = output.sigmoid().numpy()\n            binary_labels = (np.sum(data.y.numpy()) > 0).astype(int)\n            all_labels.extend([binary_labels])\n            all_preds.extend(output_sigmoid.max(axis=1))  # Using max of three class, assuming positive correlation\n    \n    all_labels = np.array(all_labels)\n    all_preds = np.array(all_preds)\n    \n    #fpr, tpr, _ = roc_curve(all_labels, all_preds)\n    #roc_auc = auc(fpr, tpr)\n    \n    #plt.figure()\n    #plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    #plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    #plt.xlim([0.0, 1.0])\n    #plt.ylim([0.0, 1.05])\n    #plt.xlabel('False Positive Rate')\n    #plt.ylabel('True Positive Rate')\n    #plt.title('Receiver Operating Characteristic')\n    #plt.legend(loc=\"lower right\")\n    #plt.show()\n    return all_labels, all_preds\n\nlanels_, preds_ = evaluate_model(test_graph_converted)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T09:03:21.247631Z","iopub.execute_input":"2024-06-19T09:03:21.247919Z","iopub.status.idle":"2024-06-19T09:07:30.762372Z","shell.execute_reply.started":"2024-06-19T09:03:21.247894Z","shell.execute_reply":"2024-06-19T09:07:30.761348Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#check output in preds_\npreds_[:5]","metadata":{"execution":{"iopub.status.busy":"2024-06-19T09:07:30.763603Z","iopub.execute_input":"2024-06-19T09:07:30.763904Z","iopub.status.idle":"2024-06-19T09:07:30.769003Z","shell.execute_reply.started":"2024-06-19T09:07:30.763874Z","shell.execute_reply":"2024-06-19T09:07:30.768233Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"array([0.45535064, 0.4564259 , 0.455285  , 0.45541528, 0.4551936 ],\n      dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"threshold = np.round(preds_[0],4) - 0.03\nstepsize = 0.0001\nmatch_lst = []\nthreshold_lst = []\nhigh_thr, high_match = -1, -1\nlow_thr, low_match = 1, 1\ncounter, last_match = 0, 0\nwhile threshold <=np.round(preds_[0],4) + 0.03:\n    binary_pred_ = [1 if x <= threshold else 0 for x in preds_]\n    match = np.round(np.mean([1 if x==y else 0 for x,y in zip(binary_pred_, lanels_)]),4)\n    #if 0.481<= threshold <= 0.482: \n        #print(f'threshold: {np.round(threshold,4)}, accuracy: {match}')\n        \n    if match > best_match: #update best-accuracy threshold\n        high_match = match\n        high_thr = np.round(threshold,5)\n        \n    elif match < low_match: #early stop if accuracy is dropping continuously\n        low_match = match\n        low_thr = np.round(threshold,5)\n        \n    match_lst.append(match)\n    threshold_lst.append(np.round(threshold,4))\n    threshold += stepsize\nprint('DONE')\n\nplt.figure()\nplt.plot(threshold_lst, match_lst, color='darkorange', lw=2, label='acc')\nplt.xlabel('Threshold')\nplt.ylabel('Accuracy')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-19T09:35:41.813232Z","iopub.execute_input":"2024-06-19T09:35:41.814020Z","iopub.status.idle":"2024-06-19T09:36:04.753571Z","shell.execute_reply.started":"2024-06-19T09:35:41.813978Z","shell.execute_reply":"2024-06-19T09:36:04.752927Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"DONE\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"print(high_match, high_thr, low_match, low_thr)\nmatch_diff_h, match_diff_l = abs(high_match)-0.5, abs(low_match-0.5)\nprint(match_diff_h, match_diff_l)\nif high_match == -1 or match_diff_h < match_diff_l:\n    rev = 1\n\nelse:\n    rev = 0\n    \nrev\n","metadata":{"execution":{"iopub.status.busy":"2024-06-19T09:46:16.403440Z","iopub.execute_input":"2024-06-19T09:46:16.403850Z","iopub.status.idle":"2024-06-19T09:46:16.410433Z","shell.execute_reply.started":"2024-06-19T09:46:16.403819Z","shell.execute_reply":"2024-06-19T09:46:16.409806Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"-1 -1 0.4245 0.455\n0.5 0.07550000000000001\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"code","source":"# Prediction test\nimport random\nfor i in range(10):\n    print(predict_label(test_graph_converted[i]))","metadata":{"execution":{"iopub.status.busy":"2024-06-19T09:18:59.561149Z","iopub.status.idle":"2024-06-19T09:18:59.561470Z","shell.execute_reply.started":"2024-06-19T09:18:59.561321Z","shell.execute_reply":"2024-06-19T09:18:59.561337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Convert SMILES to graph objects\nPACK_NODE_DIM=9\nPACK_EDGE_DIM=1\nNODE_DIM=PACK_NODE_DIM*8\nEDGE_DIM=PACK_EDGE_DIM*8\n\ndef one_of_k_encoding(x, allowable_set, allow_unk=False):\n    if x not in allowable_set:\n        if allow_unk:\n            x = allowable_set[-1]\n        else:\n            raise Exception(f'input {x} not in allowable set{allowable_set}!!!')\n    return list(map(lambda s: x == s, allowable_set))\n\n\n#Get features of an atom (one-hot encoding:)\n'''\n    1.atom element: 44+1 dimensions    \n    2.the atom's hybridization: 5 dimensions\n    3.degree of atom: 6 dimensions                        \n    4.total number of H bound to atom: 6 dimensions\n    5.number of implicit H bound to atom: 6 dimensions    \n    6.whether the atom is on ring: 1 dimension\n    7.whether the atom is aromatic: 1 dimension           \n    Total: 70 dimensions\n'''\n\nATOM_SYMBOL = [\n    'C', 'N', 'O', 'S', 'F', 'Si', 'P', 'Cl', 'Br', 'Mg',\n    'Na', 'Ca', 'Fe', 'As', 'Al', 'I', 'B', 'V', 'K', 'Tl',\n    'Yb', 'Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se', 'Ti', 'Zn', 'H',\n    'Li', 'Ge', 'Cu', 'Au', 'Ni', 'Cd', 'In', 'Mn', 'Zr', 'Cr',\n    'Pt', 'Hg', 'Pb', 'Dy',\n    #'Unknown'\n]\n#print('ATOM_SYMBOL', len(ATOM_SYMBOL))44\nHYBRIDIZATION_TYPE = [\n    Chem.rdchem.HybridizationType.S,\n    Chem.rdchem.HybridizationType.SP,\n    Chem.rdchem.HybridizationType.SP2,\n    Chem.rdchem.HybridizationType.SP3,\n    Chem.rdchem.HybridizationType.SP3D\n]\n\ndef get_atom_feature(atom):\n    feature = (\n        one_of_k_encoding(atom.GetSymbol(), ATOM_SYMBOL)\n       + one_of_k_encoding(atom.GetHybridization(), HYBRIDIZATION_TYPE)\n       + one_of_k_encoding(atom.GetDegree(), [0, 1, 2, 3, 4, 5])\n       + one_of_k_encoding(atom.GetTotalNumHs(), [0, 1, 2, 3, 4, 5])\n       + one_of_k_encoding(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5])\n       + [atom.IsInRing()]\n       + [atom.GetIsAromatic()]\n    )\n    #feature = np.array(feature, dtype=np.uint8)\n    feature = np.packbits(feature)\n    return feature\n\n\n#Get features of an edge (one-hot encoding)\n'''\n    1.single/double/triple/aromatic: 4 dimensions       \n    2.the atom's hybridization: 1 dimensions\n    3.whether the bond is on ring: 1 dimension          \n    Total: 6 dimensions\n'''\n\ndef get_bond_feature(bond):\n    bond_type = bond.GetBondType()\n    feature = [\n        bond_type == Chem.rdchem.BondType.SINGLE,\n        bond_type == Chem.rdchem.BondType.DOUBLE,\n        bond_type == Chem.rdchem.BondType.TRIPLE,\n        bond_type == Chem.rdchem.BondType.AROMATIC,\n        bond.GetIsConjugated(),\n        bond.IsInRing()\n    ]\n    #feature = np.array(feature, dtype=np.uint8)\n    feature = np.packbits(feature)\n    return feature\n\n\ndef smile_to_graph(smiles):\n    mol = Chem.MolFromSmiles(smiles)\n    N = mol.GetNumAtoms()\n    node_feature = []\n    edge_feature = []\n    edge = []\n    for i in range(mol.GetNumAtoms()):\n        atom_i = mol.GetAtomWithIdx(i)\n        atom_i_features = get_atom_feature(atom_i)\n        node_feature.append(atom_i_features)\n\n        for j in range(mol.GetNumAtoms()):\n            bond_ij = mol.GetBondBetweenAtoms(i, j)\n            if bond_ij is not None:\n                edge.append([i, j])\n                bond_features_ij = get_bond_feature(bond_ij)\n                edge_feature.append(bond_features_ij)\n    node_feature=np.stack(node_feature)\n    edge_feature=np.stack(edge_feature)\n    edge = np.array(edge,dtype=np.uint8)\n    return N,edge,node_feature,edge_feature\n\ndef to_pyg_format(N,edge,node_feature,edge_feature):\n    graph = Data(\n        idx=-1,\n        edge_index = torch.from_numpy(edge.T).int(),\n        x          = torch.from_numpy(node_feature).byte(),\n        edge_attr  = torch.from_numpy(edge_feature).byte(),\n    )\n    return graph\n\n#debug one example\ng = to_pyg_format(*smile_to_graph(smiles=\"C#CCOc1ccc(CNc2nc(NCc3cccc(Br)n3)nc(N[C@@H](CC#C)CC(=O)NC)n2)cc1\"))\nprint(g)\nprint('[Dy] is replaced by C !!')\nprint('smile_to_graph() ok!')","metadata":{"execution":{"iopub.status.busy":"2024-06-19T09:18:59.562891Z","iopub.status.idle":"2024-06-19T09:18:59.563220Z","shell.execute_reply.started":"2024-06-19T09:18:59.563057Z","shell.execute_reply":"2024-06-19T09:18:59.563074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediction function\ndef predict_label(data):\n    model.eval()\n    output = model(data)\n    labels = torch.sigmoid(output).detach().numpy()\n    #predicted_label = 0 if np.mean(labels)<0.1 else 1\n    return labels#predicted_label\n\ntest_file = '/kaggle/input/leash-BELKA/test.csv'\noutput_file = 'submission_GAT.csv'  # Specify the path and filename for the output file\ncount = 0\n# Read the test.parquet file into a pandas DataFrame\nfor df_test in pd.read_csv(test_file, chunksize=100000):\n    def helper_(s):\n        return to_pyg_format(*smile_to_graph(smiles=s))\n    df_test.drop([\"buildingblock1_smiles\",\"buildingblock2_smiles\",\"buildingblock3_smiles\"],axis = 1)\n    df_test['graph'] = df_test['molecule_smiles'].apply(helper_)\n    \n\n    # \n    pred = df_test['graph'].apply(predict_label)\n    \n    # Predict the probabilities\n    def helper2(pred_ar):\n        if rev == 0:\n            if pred_ar.max(axis=1)[0] <= best_thr:\n                return 1\n            return 0\n        else:\n            if pred_ar.max(axis=1)[0] <= best_thr:\n                return 0\n            return 1\n        \n        \n    probabilities = pred.apply(helper2)\n\n    # Create a DataFrame with 'id' and 'probability' columns\n    output_df = pd.DataFrame({'id': df_test['id'], 'binds': probabilities})\n\n    # Save the output DataFrame to a CSV file\n    output_df.to_csv(output_file, index=False, mode='a', header=not os.path.exists(output_file))\n    count += 1\n    print('iteration completed: ',count)\nprint('DONE')","metadata":{"execution":{"iopub.status.busy":"2024-06-19T09:18:59.564360Z","iopub.status.idle":"2024-06-19T09:18:59.564673Z","shell.execute_reply.started":"2024-06-19T09:18:59.564529Z","shell.execute_reply":"2024-06-19T09:18:59.564544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"import pandas as pd\nimport torch\nimport torch_xla\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.parallel_loader as pl\nimport numpy as np\nimport os\n\n# Ensure torch_xla is installed (uncomment if needed)\n# !pip install torch_xla\n\n# Define the predict_label function\ndef predict_label(data):\n    model.eval()\n    data = data.to(xm.xla_device())  # Move data to TPU device\n    output = model(data)\n    labels = torch.sigmoid(output).detach().cpu().numpy()  # Move output back to CPU\n    return labels\n\n# Paths to input and output files\ntest_file = '/kaggle/input/leash-BELKA/test.csv'\noutput_file = 'submission_GAT.csv'\n\n# Counter for iterations\ncount = 0\n\n# Function to convert SMILES to graph\ndef helper_(s):\n    return to_pyg_format(*smile_to_graph(smiles=s))\n\n# Function to convert prediction array to label\ndef helper2(pred_ar):\n    if pred_ar.max(axis=1)[0] <= 0.4819:\n        return 1\n    return 0\n\n# Initialize TPU device\ndevice = xm.xla_device()\n\n# Move the pre-trained model to TPU\nmodel1 = model.to(device)\n\n# Read the test.csv file in chunks\nfor df_test in pd.read_csv(test_file, chunksize=100000):\n    # Drop unnecessary columns\n    df_test = df_test.drop([\"buildingblock1_smiles\", \"buildingblock2_smiles\", \"buildingblock3_smiles\"], axis=1)\n    \n    # Apply the helper_ function to create graph representations\n    df_test['graph'] = df_test['molecule_smiles'].apply(helper_)\n    \n    # Predict the labels\n    pred = df_test['graph'].apply(predict_label)\n    probabilities = pred.apply(helper2)\n    \n    # Create a DataFrame with 'id' and 'binds' columns\n    output_df = pd.DataFrame({'id': df_test['id'], 'binds': probabilities})\n    \n    # Save the output DataFrame to a CSV file\n    output_df.to_csv(output_file, index=False, mode='a', header=not os.path.exists(output_file))\n    \n    # Increment the iteration counter\n    count += 1\n    print('Iteration completed:', count)\n\nprint('DONE')","metadata":{"execution":{"iopub.status.busy":"2024-06-19T07:44:04.557057Z","iopub.execute_input":"2024-06-19T07:44:04.557942Z"}}},{"cell_type":"code","source":"print('END OF CODE')","metadata":{"execution":{"iopub.status.busy":"2024-06-19T09:18:59.565526Z","iopub.status.idle":"2024-06-19T09:18:59.566041Z","shell.execute_reply.started":"2024-06-19T09:18:59.565878Z","shell.execute_reply":"2024-06-19T09:18:59.565895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"import tensorflow as tf\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\nexcept ValueError:\n    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n\ntpu_strategy = tf.distribute.TPUStrategy(tpu)\nprint('TPU activated successfully')","metadata":{"execution":{"iopub.status.busy":"2024-06-18T03:12:45.862190Z","iopub.execute_input":"2024-06-18T03:12:45.862516Z"}}},{"cell_type":"code","source":"# Prediction test\n\n#predict_label(to_pyg_list_test([test_graph_sample[1]])[0])","metadata":{"execution":{"iopub.status.busy":"2024-06-19T09:18:59.566749Z","iopub.status.idle":"2024-06-19T09:18:59.567051Z","shell.execute_reply.started":"2024-06-19T09:18:59.566900Z","shell.execute_reply":"2024-06-19T09:18:59.566916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#to_pyg_list_test([test_graph_sample[0]])\n\n#test_graph_converted = to_pyg_list(test_graph_sample)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T09:18:59.567957Z","iopub.status.idle":"2024-06-19T09:18:59.568287Z","shell.execute_reply.started":"2024-06-19T09:18:59.568127Z","shell.execute_reply":"2024-06-19T09:18:59.568143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"from sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\n\ndef evaluate_model(test_set, test_bind):\n    model.eval()\n    all_labels = []\n    all_preds = []\n    \n    with torch.no_grad():\n        for i in range(5):#len(test_set):\n            output = model(test_set[i])\n            all_labels.append(test_bind[i])\n            all_preds.append(output.sigmoid().numpy())\n            \n    #all_labels = np.concatenate(all_labels, axis=0)\n    #all_preds = np.concatenate(all_preds, axis=0)\n    \n    return all_labels, all_preds\nprint((evaluate_model(test_graph_sample, test_bind_sample)[1][0]>= 0.5).astype(int))","metadata":{}},{"cell_type":"markdown","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GATConv, global_mean_pool as gmp\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm import tqdm\n\ndef evaluate_model(test_set):\n    model.eval()\n    all_labels = []\n    all_preds = []\n    \n    with torch.no_grad():\n        for data in test_set:\n            output = model(data)\n            output_sigmoid = output.sigmoid().numpy()\n            binary_labels = (np.sum(data.y.numpy()) > 0).astype(int)\n            all_labels.extend([binary_labels])\n            all_preds.extend(output_sigmoid.max(axis=1))  # Using max of three class, assuming positive correlation\n    \n    all_labels = np.array(all_labels)\n    all_preds = np.array(all_preds)\n    \n    fpr, tpr, _ = roc_curve(all_labels, all_preds)\n    roc_auc = auc(fpr, tpr)\n    \n    plt.figure()\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    return all_labels, all_preds\n\nlanels_, preds_ = evaluate_model(test_graph_wlabel)","metadata":{}},{"cell_type":"markdown","source":"threshold = 0.39\nstepsize = 0.0005\nmatch_lst = []\nthreshold_lst = []\nwhile threshold <=0.43:\n    binary_pred_ = [1 if x >= threshold else 0 for x in preds_]\n    match = np.round(np.mean([1 if x==y else 0 for x,y in zip(binary_pred_, lanels_)]),4)\n    if 0.415>= threshold >= 0.405: \n        print(f'threshold: {np.round(threshold,4)}, accuracy: {match}')\n    match_lst.append(match)\n    threshold_lst.append(np.round(threshold,4))\n    threshold += stepsize\nprint('DONE')\n\nplt.figure()\nplt.plot(threshold_lst, match_lst, color='darkorange', lw=2, label='acc')\nplt.xlabel('Threshold')\nplt.ylabel('Accuracy')\nplt.show()","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Graph NN Code Repo","metadata":{"execution":{"iopub.status.busy":"2024-06-19T09:18:59.569063Z","iopub.status.idle":"2024-06-19T09:18:59.569510Z","shell.execute_reply.started":"2024-06-19T09:18:59.569299Z","shell.execute_reply":"2024-06-19T09:18:59.569333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"import numpy as np\n\nimport rdkit\nfrom rdkit import Chem\n\nimport torch\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\n\nfrom torch_geometric.nn import MessagePassing, global_mean_pool\nfrom torch_scatter import scatter\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nprint('import ok!')","metadata":{}},{"cell_type":"markdown","source":"# helper\n# torch version of np unpackbits\n#https://gist.github.com/vadimkantorov/30ea6d278bc492abf6ad328c6965613a\n\ndef tensor_dim_slice(tensor, dim, dim_slice):\n\treturn tensor[(dim if dim >= 0 else dim + tensor.dim()) * (slice(None),) + (dim_slice,)]\n\n# @torch.jit.script\ndef packshape(shape, dim: int = -1, mask: int = 0b00000001, dtype=torch.uint8, pack=True):\n\tdim = dim if dim >= 0 else dim + len(shape)\n\tbits, nibble = (\n\t\t8 if dtype is torch.uint8 else 16 if dtype is torch.int16 else 32 if dtype is torch.int32 else 64 if dtype is torch.int64 else 0), (\n\t\t1 if mask == 0b00000001 else 2 if mask == 0b00000011 else 4 if mask == 0b00001111 else 8 if mask == 0b11111111 else 0)\n\t# bits = torch.iinfo(dtype).bits # does not JIT compile\n\tassert nibble <= bits and bits % nibble == 0\n\tnibbles = bits // nibble\n\tshape = (shape[:dim] + (int(math.ceil(shape[dim] / nibbles)),) + shape[1 + dim:]) if pack else (\n\t\t\t\tshape[:dim] + (shape[dim] * nibbles,) + shape[1 + dim:])\n\treturn shape, nibbles, nibble\n\n# @torch.jit.script\ndef F_unpackbits(tensor, dim: int = -1, mask: int = 0b00000001, shape=None, out=None, dtype=torch.uint8):\n\tdim = dim if dim >= 0 else dim + tensor.dim()\n\tshape_, nibbles, nibble = packshape(tensor.shape, dim=dim, mask=mask, dtype=tensor.dtype, pack=False)\n\tshape = shape if shape is not None else shape_\n\tout = out if out is not None else torch.empty(shape, device=tensor.device, dtype=dtype)\n\tassert out.shape == shape\n\n\tif shape[dim] % nibbles == 0:\n\t\tshift = torch.arange((nibbles - 1) * nibble, -1, -nibble, dtype=torch.uint8, device=tensor.device)\n\t\tshift = shift.view(nibbles, *((1,) * (tensor.dim() - dim - 1)))\n\t\treturn torch.bitwise_and((tensor.unsqueeze(1 + dim) >> shift).view_as(out), mask, out=out)\n\n\telse:\n\t\tfor i in range(nibbles):\n\t\t\tshift = nibble * i\n\t\t\tsliced_output = tensor_dim_slice(out, dim, slice(i, None, nibbles))\n\t\t\tsliced_input = tensor.narrow(dim, 0, sliced_output.shape[dim])\n\t\t\ttorch.bitwise_and(sliced_input >> shift, mask, out=sliced_output)\n\treturn out\n\nclass dotdict(dict):\n\t__setattr__ = dict.__setitem__\n\t__delattr__ = dict.__delitem__\n\t\n\tdef __getattr__(self, name):\n\t\ttry:\n\t\t\treturn self[name]\n\t\texcept KeyError:\n\t\t\traise AttributeError(name)\n\n            \nprint('helper ok!')","metadata":{}},{"cell_type":"markdown","source":"# mol to graph adopted from\n# from https://github.com/LiZhang30/GPCNDTA/blob/main/utils/DrugGraph.py\n\nPACK_NODE_DIM=9\nPACK_EDGE_DIM=1\nNODE_DIM=PACK_NODE_DIM*8\nEDGE_DIM=PACK_EDGE_DIM*8\n\ndef one_of_k_encoding(x, allowable_set, allow_unk=False):\n\tif x not in allowable_set:\n\t\tif allow_unk:\n\t\t\tx = allowable_set[-1]\n\t\telse:\n\t\t\traise Exception(f'input {x} not in allowable set{allowable_set}!!!')\n\treturn list(map(lambda s: x == s, allowable_set))\n\n\n#Get features of an atom (one-hot encoding:)\n'''\n\t1.atom element: 44+1 dimensions    \n\t2.the atom's hybridization: 5 dimensions\n\t3.degree of atom: 6 dimensions                        \n\t4.total number of H bound to atom: 6 dimensions\n\t5.number of implicit H bound to atom: 6 dimensions    \n\t6.whether the atom is on ring: 1 dimension\n\t7.whether the atom is aromatic: 1 dimension           \n\tTotal: 70 dimensions\n'''\n\nATOM_SYMBOL = [\n\t'C', 'N', 'O', 'S', 'F', 'Si', 'P', 'Cl', 'Br', 'Mg',\n\t'Na', 'Ca', 'Fe', 'As', 'Al', 'I', 'B', 'V', 'K', 'Tl',\n\t'Yb', 'Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se', 'Ti', 'Zn', 'H',\n\t'Li', 'Ge', 'Cu', 'Au', 'Ni', 'Cd', 'In', 'Mn', 'Zr', 'Cr',\n\t'Pt', 'Hg', 'Pb', 'Dy',\n\t#'Unknown'\n]\n#print('ATOM_SYMBOL', len(ATOM_SYMBOL))44\nHYBRIDIZATION_TYPE = [\n\tChem.rdchem.HybridizationType.S,\n\tChem.rdchem.HybridizationType.SP,\n\tChem.rdchem.HybridizationType.SP2,\n\tChem.rdchem.HybridizationType.SP3,\n\tChem.rdchem.HybridizationType.SP3D\n]\n\ndef get_atom_feature(atom):\n\tfeature = (\n\t\t one_of_k_encoding(atom.GetSymbol(), ATOM_SYMBOL)\n\t   + one_of_k_encoding(atom.GetHybridization(), HYBRIDIZATION_TYPE)\n\t   + one_of_k_encoding(atom.GetDegree(), [0, 1, 2, 3, 4, 5])\n\t   + one_of_k_encoding(atom.GetTotalNumHs(), [0, 1, 2, 3, 4, 5])\n\t   + one_of_k_encoding(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5])\n\t   + [atom.IsInRing()]\n\t   + [atom.GetIsAromatic()]\n\t)\n\t#feature = np.array(feature, dtype=np.uint8)\n\tfeature = np.packbits(feature)\n\treturn feature\n\n\n#Get features of an edge (one-hot encoding)\n'''\n\t1.single/double/triple/aromatic: 4 dimensions       \n\t2.the atom's hybridization: 1 dimensions\n\t3.whether the bond is on ring: 1 dimension          \n\tTotal: 6 dimensions\n'''\n\ndef get_bond_feature(bond):\n\tbond_type = bond.GetBondType()\n\tfeature = [\n\t\tbond_type == Chem.rdchem.BondType.SINGLE,\n\t\tbond_type == Chem.rdchem.BondType.DOUBLE,\n\t\tbond_type == Chem.rdchem.BondType.TRIPLE,\n\t\tbond_type == Chem.rdchem.BondType.AROMATIC,\n\t\tbond.GetIsConjugated(),\n\t\tbond.IsInRing()\n\t]\n\t#feature = np.array(feature, dtype=np.uint8)\n\tfeature = np.packbits(feature)\n\treturn feature\n\n\ndef smile_to_graph(smiles):\n\tmol = Chem.MolFromSmiles(smiles)\n\tN = mol.GetNumAtoms()\n\tnode_feature = []\n\tedge_feature = []\n\tedge = []\n\tfor i in range(mol.GetNumAtoms()):\n\t\tatom_i = mol.GetAtomWithIdx(i)\n\t\tatom_i_features = get_atom_feature(atom_i)\n\t\tnode_feature.append(atom_i_features)\n\n\t\tfor j in range(mol.GetNumAtoms()):\n\t\t\tbond_ij = mol.GetBondBetweenAtoms(i, j)\n\t\t\tif bond_ij is not None:\n\t\t\t\tedge.append([i, j])\n\t\t\t\tbond_features_ij = get_bond_feature(bond_ij)\n\t\t\t\tedge_feature.append(bond_features_ij)\n\tnode_feature=np.stack(node_feature)\n\tedge_feature=np.stack(edge_feature)\n\tedge = np.array(edge,dtype=np.uint8)\n\treturn N,edge,node_feature,edge_feature\n\ndef to_pyg_format(N,edge,node_feature,edge_feature):\n\tgraph = Data(\n\t\tidx=-1,\n\t\tedge_index = torch.from_numpy(edge.T).int(),\n\t\tx          = torch.from_numpy(node_feature).byte(),\n\t\tedge_attr  = torch.from_numpy(edge_feature).byte(),\n\t)\n\treturn graph\n\n#debug one example\ng = to_pyg_format(*smile_to_graph(smiles=\"C#CCOc1ccc(CNc2nc(NCc3cccc(Br)n3)nc(N[C@@H](CC#C)CC(=O)NC)n2)cc1\"))\nprint(g)\nprint('[Dy] is replaced by C !!')\nprint('smile_to_graph() ok!')","metadata":{}},{"cell_type":"markdown","source":"print('DONE')","metadata":{}},{"cell_type":"markdown","source":"import numpy as np\n\nimport rdkit\nfrom rdkit import Chem\n\nimport torch\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\n\nfrom torch_geometric.nn import MessagePassing, global_mean_pool\nfrom torch_scatter import scatter\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nprint('import ok!')","metadata":{}},{"cell_type":"markdown","source":"pip install rdkit","metadata":{}},{"cell_type":"markdown","source":"DEVICE='cpu'\n\n# i have removed all comments here to jepp it clean. refer to orginal link for code comments\n# of MPNNModel\nclass MPNNLayer(MessagePassing):\n\tdef __init__(self, emb_dim=64, edge_dim=4, aggr='add'):\n\t\tsuper().__init__(aggr=aggr)\n\n\t\tself.emb_dim = emb_dim\n\t\tself.edge_dim = edge_dim\n\t\tself.mlp_msg = nn.Sequential(\n\t\t\tnn.Linear(2 * emb_dim + edge_dim, emb_dim), nn.BatchNorm1d(emb_dim), nn.ReLU(),\n\t\t\tnn.Linear(emb_dim, emb_dim), nn.BatchNorm1d(emb_dim), nn.ReLU()\n\t\t)\n\t\tself.mlp_upd = nn.Sequential(\n\t\t\tnn.Linear(2 * emb_dim, emb_dim), nn.BatchNorm1d(emb_dim), nn.ReLU(),\n\t\t\tnn.Linear(emb_dim, emb_dim), nn.BatchNorm1d(emb_dim), nn.ReLU()\n\t\t)\n\n\tdef forward(self, h, edge_index, edge_attr):\n\t\tout = self.propagate(edge_index, h=h, edge_attr=edge_attr)\n\t\treturn out\n\n\tdef message(self, h_i, h_j, edge_attr):\n\t\tmsg = torch.cat([h_i, h_j, edge_attr], dim=-1)\n\t\treturn self.mlp_msg(msg)\n\n\tdef aggregate(self, inputs, index):\n\t\treturn scatter(inputs, index, dim=self.node_dim, reduce=self.aggr)\n\n\tdef update(self, aggr_out, h):\n\t\tupd_out = torch.cat([h, aggr_out], dim=-1)\n\t\treturn self.mlp_upd(upd_out)\n\n\tdef __repr__(self) -> str:\n\t\treturn (f'{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})')\n\n\nclass MPNNModel(nn.Module):\n    def __init__(self, num_layers=3, emb_dim=64, in_dim=11, edge_dim=4, out_dim=1):\n        super().__init__()\n\n        self.lin_in = nn.Linear(in_dim, emb_dim)\n\n        # Stack of MPNN layers\n        self.convs = torch.nn.ModuleList()\n        for layer in range(num_layers):\n            self.convs.append(MPNNLayer(emb_dim, edge_dim, aggr='add'))\n\n        self.pool = global_mean_pool\n\n    def forward(self, data): #PyG.Data - batch of PyG graphs\n\n        h = self.lin_in(F_unpackbits(data.x,-1).float())  \n\n        for conv in self.convs:\n            h = h + conv(h, data.edge_index.long(), F_unpackbits(data.edge_attr,-1).float())  # (n, d) -> (n, d)\n\n        h_graph = self.pool(h, data.batch)  \n        return h_graph\n\n# our prediction model here !!!!\nclass Net(nn.Module):\n    def __init__(self, ):\n        super().__init__()\n\n        self.output_type = ['infer', 'loss']\n\n        graph_dim=96\n        self.smile_encoder = MPNNModel(\n            in_dim=NODE_DIM, edge_dim=EDGE_DIM, emb_dim=graph_dim, num_layers=4,\n        )\n        self.bind = nn.Sequential(\n            nn.Linear(graph_dim, 1024),\n            #nn.BatchNorm1d(1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.1),\n            nn.Linear(1024, 1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.1),\n            nn.Linear(1024, 512),\n            #nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.1),\n            nn.Linear(512, 3),\n        )\n\n    def forward(self, batch):\n        graph = batch['graph']\n        x = self.smile_encoder(graph) \n        bind = self.bind(x)\n\n        # --------------------------\n        output = {}\n        if 'loss' in self.output_type:\n            target = batch['bind']\n            output['bce_loss'] = F.binary_cross_entropy_with_logits(bind.float(), target.float())\n        if 'infer' in self.output_type:\n            output['bind'] = torch.sigmoid(bind)\n\n        return output\n    \nprint('Create Model OK!')","metadata":{}},{"cell_type":"markdown","source":"#debug: make some dummy data and run\n\ndef run_check_net():\n\tbatch_size = 3\n\tnode_dim=NODE_DIM\n\tedge_dim=EDGE_DIM\n\n\tdata = []\n\tfor b in range(batch_size):\n\t\tN = np.random.randint(5,10)\n\t\tE = np.random.randint(3,N*(N-1))\n\t\tedge_index = np.stack([\n\t\t\tnp.random.choice(N, E, replace=True),\n\t\t\tnp.random.choice(N, E, replace=True),\n\t\t]).T\n\t\tedge_index = np.sort(edge_index)\n\t\tedge_index = edge_index[edge_index[:, 0].argsort()]\n\t\tedge_index[0] = [0,1] #default\n\t\tedge_index = edge_index[edge_index[:,0]!=edge_index[:,1]]\n\t\tedge_index = np.unique(edge_index, axis=0)\n\n\t\tE = len(edge_index)\n\t\tedge_index = np.ascontiguousarray(edge_index.T)\n\n\t\td = Data(\n\t\t\tidx        = b,\n\t\t\tedge_index = torch.from_numpy(edge_index).int(),\n\t\t\tx          = torch.from_numpy(np.packbits(np.random.choice(2, (N, node_dim)),-1)).byte(),\n\t\t\tedge_attr  = torch.from_numpy(np.packbits(np.random.choice(2, (E, edge_dim)),-1)).byte(),\n\t\t)\n\t\tdata.append(d)\n\n\t#from my_mol2graph import make_dummy_data\n\t#data = make_dummy_data()\n\n\tloader = DataLoader(data, batch_size=batch_size)\n\tgraph = next(iter(loader))\n\tidx = graph.idx.tolist()  #use to index bind array\n\tbatch = dotdict( \n\t\tgraph = graph.to(DEVICE),\n\t\tbind  = torch.from_numpy(np.random.choice(2, (batch_size, 3))).float().to(DEVICE),\n\t)\n\tzz=0\n \n\tnet = Net().to(DEVICE)\n\t#print(net)\n\n\twith torch.no_grad():\n\t\twith torch.cuda.amp.autocast(enabled=True): # dtype=torch.float16):\n\t\t\toutput = net(batch)\n\t\t\t#print(output['bind'])\n\n\t# ---\n\tprint('batch')\n\tfor k, v in batch.items():\n\t\tif k=='idx':\n\t\t\tprint(f'{k:>32} : {len(v)} ')\n\t\telif k=='graph':\n\t\t\tprint(f'{k:>32} : {graph} ')\n\t\telse:\n\t\t\tprint(f'{k:>32} : {v.shape} ')\n\n\tprint('output')\n\tfor k, v in output.items():\n\t\tif 'loss' not in k:\n\t\t\tprint(f'{k:>32} : {v.shape} ')\n\tprint('loss')\n\tfor k, v in output.items():\n\t\tif 'loss' in k:\n\t\t\tprint(f'{k:>32} : {v.item()} ')\n\n            \nrun_check_net()\nprint('model ok!')","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"def my_collate(graph, index=None, device='cpu'):\n    if index is None:\n        index = np.arange(len(graph)).tolist()\n    batch = dotdict(\n        x=[],\n        edge_index=[],\n        edge_attr=[],\n        batch=[],\n        idx=index\n    )\n    offset = 0\n    for b, i in enumerate(index):\n        N, edge, node_feature, edge_feature = graph[i]\n        batch.x.append(node_feature)\n        batch.edge_attr.append(edge_feature)\n        batch.edge_index.append(edge.astype(int) + offset)\n        batch.batch += N * [b]\n        offset += N\n    batch.x = torch.from_numpy(np.concatenate(batch.x)).to(device)\n    batch.edge_attr = torch.from_numpy(np.concatenate(batch.edge_attr)).to(device)\n    batch.edge_index = torch.from_numpy(np.concatenate(batch.edge_index).T).to(device)\n    batch.batch = torch.LongTensor(batch.batch).to(device)\n    return batch\n\n\n#.... more code here ....\n\nwhile epoch<cfg.num_epoch:\n    shuffled_idx = train_idx.copy()\n    np.random.shuffle(shuffled_idx)\n    for t, index in enumerate(np.arange(0,len(shuffled_idx),cfg.train_batch_size)):\n        index = shuffled_idx[index:index+cfg.train_batch_size]\n        if len(index)!=cfg.train_batch_size: continue #drop last\n\n        B = len(index)\n        batch = dotdict(\n            graph = my_collate(train_graph,index,device='cuda'),\n            bind = torch.from_numpy(train_bind[index]).float().cuda(),\n        )\n\n        net.train()\n        net.output_type = ['loss', 'infer']\n\n        with torch.cuda.amp.autocast(enabled=cfg.is_amp):\n            output = net(batch)  #data_parallel(net,batch) #\n            bce_loss = output['bce_loss']","metadata":{}},{"cell_type":"markdown","source":"from multiprocessing import Pool\nfrom tqdm import tqdm\nimport gc\nfrom torch_geometric.loader import DataLoader as PyGDataLoader\n\ndef to_pyg_list(graph):\n\tL = len(graph)\n\tfor i in tqdm(range(L)):\n\t\tN, edge, node_feature, edge_feature = graph[i]\n\t\tgraph[i] = Data(\n\t\t\tidx=i,\n\t\t\tedge_index=torch.from_numpy(edge.T).int(),\n\t\t\tx=torch.from_numpy(node_feature).byte(),\n\t\t\tedge_attr=torch.from_numpy(edge_feature).byte(),\n\t\t)\n\treturn graph\n\n\ntrain_smiles=[ #replace [Dy] with C\n    \"C#CCOc1ccc(CNc2nc(NCc3cccc(Br)n3)nc(N[C@@H](CC#C)CC(=O)NC)n2)cc1\",\n    \"C#CCOc1ccc(CNc2nc(NCc3cccc(Br)n3)nc(N[C@@H](CC#C)CC(=O)NC)n2)cc1\",\n    \"C#CCOc1ccc(CNc2nc(NCc3cccc(Br)n3)nc(N[C@@H](CC#C)CC(=O)NC)n2)cc1\",\n    \"C#CCOc1ccc(CNc2nc(NCc3cccc(Br)n3)nc(N[C@@H](CC#C)CC(=O)NC)n2)cc1\",\n    \"C#CCOc1ccc(CNc2nc(NCc3cccc(Br)n3)nc(N[C@@H](CC#C)CC(=O)NC)n2)cc1\",\n    \"C#CCOc1ccc(CNc2nc(NCc3cccc(Br)n3)nc(N[C@@H](CC#C)CC(=O)NC)n2)cc1\",\n]\ntrain_bind =np.array([\n    [0,0,0],[1,0,0],[0,1,0],[0,0,1],[1,1,0],[0,0,0],\n])\nnum_train= len(train_smiles)\nwith Pool(processes=64) as pool:\n    train_graph = list(tqdm(pool.imap(smile_to_graph, train_smiles), total=num_train))\n\ntrain_graph = to_pyg_list(train_graph)\ntrain_loader = PyGDataLoader(train_graph, batch_size=3, shuffle=True)\n\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## example training loop\nscaler = torch.cuda.amp.GradScaler(enabled=True)\nnet = Net()\nnet.to(DEVICE)\n\noptimizer =\\\n\ttorch.optim.AdamW(filter(lambda p: p.requires_grad, net.parameters()), lr=0.001)\n\nnum_epoch=10\nepoch=0\niteration=0\nwhile epoch<num_epoch: \n\tfor t, graph_batch in enumerate(train_loader): \n\t\tindex = graph_batch.idx.tolist()\n\t\tB = len(index)\n\t\tbatch = dotdict(\n\t\t\tgraph  = graph_batch.to(DEVICE),\n\t\t\tbind   = torch.from_numpy(train_bind[index]).to(DEVICE),\n\t\t)\n\n\t\tnet.train()\n\t\tnet.output_type = ['loss', 'infer']\n\t\twith torch.cuda.amp.autocast(enabled=True):\n\t\t\toutput = net(batch)  #data_parallel(net,batch) #\n\t\t\tbce_loss = output['bce_loss']\n\n\t\toptimizer.zero_grad() \n\t\tscaler.scale(bce_loss).backward() \n\t\tscaler.step(optimizer)\n\t\tscaler.update()\n\t\t \n\t\ttorch.clear_autocast_cache()\n\t\tprint(epoch,iteration,bce_loss.item())\n\t\titeration +=  1\n        \n\tepoch += 1","metadata":{}},{"cell_type":"markdown","source":"train_path ='/kaggle/input/leash-BELKA/train.parquet'\n\ncon = duckdb.connect()\ndf_train = con.query(f\"\"\"(SELECT *\n                        FROM parquet_scan('{train_path}')\n                        WHERE binds = 0\n                        ORDER BY random()\n                        LIMIT 30000)\n                        UNION ALL\n                        (SELECT *\n                        FROM parquet_scan('{train_path}')\n                        WHERE binds = 1\n                        ORDER BY random()\n                        LIMIT 30000)\"\"\").df()\ncon.close()\nprint('DONE!')","metadata":{}},{"cell_type":"markdown","source":"df_train.head()","metadata":{}},{"cell_type":"markdown","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import Sequential, Linear, ReLU\nfrom torch_geometric.nn import GATConv\nfrom torch_geometric.nn import global_max_pool as gmp\n\n# GAT  model\nclass GATNet(torch.nn.Module):\n    def __init__(self, num_features=112, n_output=1,n_filters=32, embed_dim=128, output_dim=128, dropout=0.2):\n        super(GATNet, self).__init__()\n\n        # graph layers\n        self.gcn1 = GATConv(num_features, num_features, heads=10, dropout=dropout)\n        self.gcn2 = GATConv(num_features * 10, output_dim, dropout=dropout)\n        self.fc_g1 = nn.Linear(output_dim, output_dim)\n\n        # combined layers\n        self.fc1 = nn.Linear(output_dim, 64)\n        self.fc2 = nn.Linear(64, 32)\n        self.out = nn.Linear(32, n_output)\n\n        # activation and regularization\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, data):\n        # graph input feed-forward\n        x, edge_index, batch = data.x.float(), data.edge_index, data.batch\n\n        x = F.dropout(x, p=0.2, training=self.training)\n        x = F.elu(self.gcn1(x, edge_index))\n        x = F.dropout(x, p=0.2, training=self.training)\n        x = self.gcn2(x, edge_index)\n        x = self.relu(x)\n        x = gmp(x, batch)          # global max pooling\n        x = self.fc_g1(x)\n        x = self.relu(x)\n\n       \n        # add some dense layers\n        xc = self.fc1(x)\n        xc = self.relu(xc)\n        xc = self.dropout(xc)\n        xc = self.fc2(xc)\n        xc = self.relu(xc)\n        xc = self.dropout(xc)\n        out = self.out(xc)\n        return out","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}