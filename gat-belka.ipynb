{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":67356,"databundleVersionId":8006601,"sourceType":"competition"},{"sourceId":8519891,"sourceType":"datasetVersion","datasetId":4784530}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Launch Kaggle TPU session\nprint('Session Start!')","metadata":{"execution":{"iopub.status.busy":"2024-06-06T14:25:00.737312Z","iopub.execute_input":"2024-06-06T14:25:00.737624Z","iopub.status.idle":"2024-06-06T14:25:00.746494Z","shell.execute_reply.started":"2024-06-06T14:25:00.737596Z","shell.execute_reply":"2024-06-06T14:25:00.745923Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Session Start!\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torch_geometric\n!pip install indexed_bzip2\n!pip install rdkit","metadata":{"execution":{"iopub.status.busy":"2024-06-06T14:25:19.015419Z","iopub.execute_input":"2024-06-06T14:25:19.015759Z","iopub.status.idle":"2024-06-06T14:25:36.743681Z","shell.execute_reply.started":"2024-06-06T14:25:19.015731Z","shell.execute_reply":"2024-06-06T14:25:36.742679Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting torch_geometric\n  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch_geometric) (2024.3.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from torch_geometric) (1.13.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/site-packages (from torch_geometric) (3.1.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from torch_geometric) (4.66.2)\nCollecting aiohttp\n  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/site-packages (from torch_geometric) (1.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch_geometric) (3.1.3)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/site-packages (from torch_geometric) (5.9.8)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from torch_geometric) (2.31.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from torch_geometric) (1.26.4)\nCollecting multidict<7.0,>=4.5\n  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting yarl<2.0,>=1.0\n  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting async-timeout<5.0,>=4.0\n  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\nCollecting frozenlist>=1.1.1\n  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->torch_geometric) (23.2.0)\nCollecting aiosignal>=1.1.2\n  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch_geometric) (2.1.5)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->torch_geometric) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->torch_geometric) (2.2.1)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->torch_geometric) (2024.2.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->torch_geometric) (3.3.2)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (3.4.0)\nInstalling collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, torch_geometric\nSuccessfully installed aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 frozenlist-1.4.1 multidict-6.0.5 torch_geometric-2.5.3 yarl-1.9.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nCollecting indexed_bzip2\n  Downloading indexed_bzip2-1.6.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: indexed_bzip2\nSuccessfully installed indexed_bzip2-1.6.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nCollecting rdkit\n  Downloading rdkit-2023.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from rdkit) (1.26.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/site-packages (from rdkit) (10.3.0)\nInstalling collected packages: rdkit\nSuccessfully installed rdkit-2023.9.6\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd\nfrom torch_geometric.data import Data, DataLoader\nfrom torch.nn import Sequential, Linear, ReLU\nfrom torch_geometric.nn import GATConv\nfrom torch_geometric.nn import global_max_pool as gmp\nimport indexed_bzip2 as ibz2\nimport os\nimport pickle\nimport rdkit\nfrom rdkit import Chem\n#from torch_scatter import scatter\nfrom multiprocessing import Pool\nfrom tqdm import tqdm\nimport gc\nfrom torch_geometric.loader import DataLoader as PyGDataLoader\nprint('import DONE!')","metadata":{"execution":{"iopub.status.busy":"2024-06-06T14:25:40.049465Z","iopub.execute_input":"2024-06-06T14:25:40.049851Z","iopub.status.idle":"2024-06-06T14:26:00.666039Z","shell.execute_reply.started":"2024-06-06T14:25:40.049816Z","shell.execute_reply":"2024-06-06T14:26:00.665107Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n","output_type":"stream"},{"name":"stdout","text":"import DONE!\n","output_type":"stream"}]},{"cell_type":"code","source":"#class GATNet(torch.nn.Module):\n#    def __init__(self, num_features=9, n_output=3,n_filters=32, embed_dim=128, output_dim=1, dropout=0.5):\n#        super(GATNet, self).__init__()\n\n        # GATConv\n#        self.gcn1 = GATConv(num_features, num_features , heads=10, dropout=dropout)\n#        self.gcn2 = GATConv(num_features * 10, output_dim, dropout=dropout)\n#        self.fc_g1 = nn.Linear(output_dim, output_dim)\n\n\n #       self.fc1 = nn.Linear(output_dim, 64)\n #       self.fc2 = nn.Linear(64, 32)\n #       self.out = nn.Linear(32, n_output)\n\n        # relu and dropout\n #       self.relu = nn.ReLU()\n #       self.dropout = nn.Dropout(dropout)\n\n #   def forward(self, data):\n #       x, edge_index, batch = data.x.float(), data.edge_index, data.batch\n\n #      x = F.dropout(x, p=0.2, training=self.training)\n #       x = F.elu(self.gcn1(x, edge_index))\n #       x = F.dropout(x, p=0.2, training=self.training)\n #       x = self.gcn2(x, edge_index)\n #       x = self.relu(x)\n #       x = gmp(x, batch)          \n #       x = self.fc_g1(x)\n #       x = self.relu(x)#\n\n        # dense layers\n #      xc = self.fc1(x)\n #       xc = self.relu(xc)\n #       xc = self.dropout(xc)\n #       xc = self.fc2(xc)\n #       xc = self.relu(xc)\n #       xc = self.dropout(xc)\n #       out = self.out(xc)\n #       return out\n    \n#model = GATNet()\n#optimizer = optim.Adam(model.parameters(), lr=0.01)\n\n#def custom_loss(output, target):\n #   loss = 0\n #   for i in range(3):  \n #       loss += F.binary_cross_entropy_with_logits(output[0][i], target[i].float())\n #   return loss / 3  \n\n\n# Training\n#def train_model(training_set):\n  #  model.train()\n #   for data in training_set:\n  #      optimizer.zero_grad()\n #       output = model(data)\n        #print(output)\n        #print(data.y)\n        #print(output[0][2].float(), data.y[0].float())\n  #      loss = custom_loss(output, data.y)#F.binary_cross_entropy_with_logits(output, data.y.view(-1, 3))\n  #      loss.backward()\n  #      optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T01:44:31.936970Z","iopub.execute_input":"2024-06-06T01:44:31.937530Z","iopub.status.idle":"2024-06-06T01:44:32.028630Z","shell.execute_reply.started":"2024-06-06T01:44:31.937492Z","shell.execute_reply":"2024-06-06T01:44:32.027756Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load Train_graph\ndef load_compressed_ibz2_pickle(file):\n    with ibz2.open(file, parallelization=os.cpu_count()) as f:\n        data = pickle.load(f)\n    return data\ngdf_train = load_compressed_ibz2_pickle(\n    '/kaggle/input/leash-bio-processed-dataset/train-replace-c-30m.graph.pickle.b2z'\n)\nprint('train_graph Loaded!')\nprint(len(gdf_train))\n\n# Load Train_bind\ntrainbind_data = np.load('/kaggle/input/leash-bio-processed-dataset/train.bind.npz')\ntrain_bind = trainbind_data['bind']\ntrainbind_data.close()\nprint('train_bind Loaded!')\nprint(len(train_bind))\n\ntrain_bind_30 = train_bind[:30000000]\nprint(len(gdf_train),len(train_bind_30))\nprint('DONE!')","metadata":{"execution":{"iopub.status.busy":"2024-06-06T14:26:08.644028Z","iopub.execute_input":"2024-06-06T14:26:08.644866Z","iopub.status.idle":"2024-06-06T14:31:07.552411Z","shell.execute_reply.started":"2024-06-06T14:26:08.644828Z","shell.execute_reply":"2024-06-06T14:31:07.551554Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"train_graph Loaded!\n30000000\ntrain_bind Loaded!\n98415610\n30000000 30000000\nDONE!\n","output_type":"stream"}]},{"cell_type":"code","source":"train_bind[:5]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T14:31:16.559572Z","iopub.execute_input":"2024-06-06T14:31:16.559951Z","iopub.status.idle":"2024-06-06T14:31:16.567968Z","shell.execute_reply.started":"2024-06-06T14:31:16.559921Z","shell.execute_reply":"2024-06-06T14:31:16.567291Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"array([[0, 0, 0],\n       [0, 0, 0],\n       [0, 0, 0],\n       [0, 0, 0],\n       [0, 0, 0]], dtype=uint8)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zipped = list(zip(gdf_train,train_bind_30))\n\npos_class = [x for x in zipped if sum(x[1]) > 0]\nneg_class = [x for x in zipped if sum(x[1]) == 0]\nprint(len(pos_class),len(neg_class))","metadata":{"execution":{"iopub.status.busy":"2024-06-06T14:31:20.364390Z","iopub.execute_input":"2024-06-06T14:31:20.365399Z","iopub.status.idle":"2024-06-06T14:34:33.625753Z","shell.execute_reply.started":"2024-06-06T14:31:20.365358Z","shell.execute_reply":"2024-06-06T14:34:33.625007Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"822875 29177125\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nrandom.shuffle(pos_class)\nrandom.shuffle(neg_class)\n\ntrain_sample = pos_class[:50000] + neg_class[:50000]\ntrain_graph_sample = []\ntrain_bind_sample = []\nfor i in train_sample:\n    train_graph_sample.append(i[0])\n    train_bind_sample.append(i[1])\n    \ntest_sample = pos_class[50000:80000] + neg_class[50000:80000]\ntest_graph_sample = []\ntest_bind_sample = []\nfor i in test_sample:\n    test_graph_sample.append(i[0])\n    test_bind_sample.append(i[1])\n    \nprint('length of train split: ',len(train_graph_sample), len(train_bind_sample))\nprint('length of test split: ',len(test_graph_sample), len(test_bind_sample))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-06T14:34:59.200413Z","iopub.execute_input":"2024-06-06T14:34:59.200826Z","iopub.status.idle":"2024-06-06T14:35:26.382242Z","shell.execute_reply.started":"2024-06-06T14:34:59.200792Z","shell.execute_reply":"2024-06-06T14:35:26.381522Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"length of train split:  100000 100000\nlength of test split:  60000 60000\n","output_type":"stream"}]},{"cell_type":"code","source":"#Create testing subset\n#train_graph_sample = gdf_train[:90000]\n#train_bind_sample = train_bind[:90000]\n#test_graph_sample = gdf_train[90000:120000]\n#test_bind_sample = train_bind[90000:120000]\n#print('trainset: ',len(train_graph_sample),len(train_bind_sample))\n#print('testset: ',len(test_graph_sample),len(test_bind_sample))","metadata":{"execution":{"iopub.status.busy":"2024-06-03T07:46:40.184223Z","iopub.execute_input":"2024-06-03T07:46:40.184560Z","iopub.status.idle":"2024-06-03T07:46:40.188258Z","shell.execute_reply.started":"2024-06-03T07:46:40.184530Z","shell.execute_reply":"2024-06-03T07:46:40.187555Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_bind_sample[-5:]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T14:35:59.376800Z","iopub.execute_input":"2024-06-06T14:35:59.377371Z","iopub.status.idle":"2024-06-06T14:35:59.383334Z","shell.execute_reply.started":"2024-06-06T14:35:59.377321Z","shell.execute_reply":"2024-06-06T14:35:59.382704Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"[array([0, 0, 0], dtype=uint8),\n array([0, 0, 0], dtype=uint8),\n array([0, 0, 0], dtype=uint8),\n array([0, 0, 0], dtype=uint8),\n array([0, 0, 0], dtype=uint8)]"},"metadata":{}}]},{"cell_type":"code","source":"#Helper: convert graph to pyg list\ndef to_pyg_list(graph):\n    L = len(graph)\n    for i in tqdm(range(L)):\n        N, edge, node_feature, edge_feature = graph[i]\n        graph[i] = Data(\n            idx=i,\n            edge_index=torch.from_numpy(edge.T).int(),\n            x=torch.from_numpy(node_feature).byte(),\n            edge_attr=torch.from_numpy(edge_feature).byte(),\n            y=torch.tensor(train_bind_sample[i])\n        )\n    return graph\n\n#Helper for test_split\ndef to_pyg_list_test(graph):\n    L = len(graph)\n    for i in tqdm(range(L)):\n        N, edge, node_feature, edge_feature = graph[i]\n        graph[i] = Data(\n            idx=i,\n            edge_index=torch.from_numpy(edge.T).int(),\n            x=torch.from_numpy(node_feature).byte(),\n            edge_attr=torch.from_numpy(edge_feature).byte()\n        )\n    return graph","metadata":{"execution":{"iopub.status.busy":"2024-06-06T14:36:02.620674Z","iopub.execute_input":"2024-06-06T14:36:02.621060Z","iopub.status.idle":"2024-06-06T14:36:02.627699Z","shell.execute_reply.started":"2024-06-06T14:36:02.621016Z","shell.execute_reply":"2024-06-06T14:36:02.626960Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"pos_class[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T06:39:02.325326Z","iopub.execute_input":"2024-06-06T06:39:02.325659Z","iopub.status.idle":"2024-06-06T06:39:02.333969Z","shell.execute_reply.started":"2024-06-06T06:39:02.325625Z","shell.execute_reply":"2024-06-06T06:39:02.333230Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converted train-graph, with label\ntrain_graph = to_pyg_list(train_graph_sample)\ntrain_graph[:5]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T14:36:15.993695Z","iopub.execute_input":"2024-06-06T14:36:15.994107Z","iopub.status.idle":"2024-06-06T14:36:49.866522Z","shell.execute_reply.started":"2024-06-06T14:36:15.994041Z","shell.execute_reply":"2024-06-06T14:36:49.865843Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"100%|██████████| 100000/100000 [00:33<00:00, 2953.32it/s]\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[Data(x=[34, 9], edge_index=[2, 72], edge_attr=[72, 1], y=[3], idx=0),\n Data(x=[40, 9], edge_index=[2, 90], edge_attr=[90, 1], y=[3], idx=1),\n Data(x=[40, 9], edge_index=[2, 84], edge_attr=[84, 1], y=[3], idx=2),\n Data(x=[40, 9], edge_index=[2, 88], edge_attr=[88, 1], y=[3], idx=3),\n Data(x=[39, 9], edge_index=[2, 88], edge_attr=[88, 1], y=[3], idx=4)]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import GATConv, global_mean_pool as gmp\nfrom tqdm import tqdm\n\nclass GATNet(torch.nn.Module):\n    def __init__(self, num_features=9, n_output=3, output_dim=32, dropout=0.5):\n        super(GATNet, self).__init__()\n\n        self.gcn1 = GATConv(num_features, num_features, heads=10, dropout=dropout)\n        self.gcn2 = GATConv(num_features * 10, output_dim, dropout=dropout)\n        self.fc_g1 = nn.Linear(output_dim, output_dim)\n\n        # add batch normalization\n        self.bn1 = nn.BatchNorm1d(output_dim)\n\n        self.fc1 = nn.Linear(output_dim, 64)\n        self.fc2 = nn.Linear(64, 32)\n        self.out = nn.Linear(32, n_output)\n\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, data):\n        x, edge_index, batch = data.x.float(), data.edge_index, data.batch\n\n        x = F.dropout(x, p=0.2, training=self.training)\n        x = F.elu(self.gcn1(x, edge_index))\n        x = F.dropout(x, p=0.2, training=self.training)\n        x = self.gcn2(x, edge_index)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = gmp(x, batch)          \n        x = self.fc_g1(x)\n        x = self.relu(x)\n\n        # Dense layers\n        xc = self.fc1(x)\n        xc = self.relu(xc)\n        xc = self.dropout(xc)\n        xc = self.fc2(xc)\n        xc = self.relu(xc)\n        xc = self.dropout(xc)\n        out = self.out(xc)\n        return out\n\nmodel = GATNet()\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  \nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n\ndef custom_loss(output, target):\n    output = output.view(-1)\n    target = target.view(-1)\n    return F.binary_cross_entropy_with_logits(output, target.float())\n\ndef train_model(training_set, batch_size=5000, epochs=20):\n    model.train()\n    dataloader = DataLoader(training_set, batch_size=batch_size, shuffle=True)\n    for epoch in range(epochs):\n        total_loss = 0\n        for data in dataloader:\n            optimizer.zero_grad()\n            output = model(data)\n            loss = custom_loss(output, data.y)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping\n            optimizer.step()\n            total_loss += loss.item()\n            \n        # update learning rate\n        scheduler.step()  \n        print(f'Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}')","metadata":{"execution":{"iopub.status.busy":"2024-06-06T14:37:00.415423Z","iopub.execute_input":"2024-06-06T14:37:00.415798Z","iopub.status.idle":"2024-06-06T14:37:00.505431Z","shell.execute_reply.started":"2024-06-06T14:37:00.415767Z","shell.execute_reply":"2024-06-06T14:37:00.504723Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# For Debug\ntraining_set = train_graph[:10000]#[Data(idx=-1, edge_index=None, x=torch.rand(5, 20), edge_attr=None, y=torch.tensor([0, 0, 1])) for _ in range(10)]\n\n# Train with the training_set\ntrain_model(training_set)\nprint('training DONE!')","metadata":{"execution":{"iopub.status.busy":"2024-06-06T14:44:44.692053Z","iopub.execute_input":"2024-06-06T14:44:44.692394Z","iopub.status.idle":"2024-06-06T14:45:15.149232Z","shell.execute_reply.started":"2024-06-06T14:44:44.692366Z","shell.execute_reply":"2024-06-06T14:45:15.148424Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 0.4197142064571381\nEpoch 2, Loss: 0.4166353434324265\nEpoch 3, Loss: 0.4143504247069359\nEpoch 4, Loss: 0.4087537035346031\nEpoch 5, Loss: 0.4025465831160545\nEpoch 6, Loss: 0.40527867078781127\nEpoch 7, Loss: 0.4092902421951294\nEpoch 8, Loss: 0.4021614983677864\nEpoch 9, Loss: 0.40142467319965364\nEpoch 10, Loss: 0.39667646735906603\nEpoch 11, Loss: 0.3971971347928047\nEpoch 12, Loss: 0.39855557680130005\nEpoch 13, Loss: 0.3960401967167854\nEpoch 14, Loss: 0.3969137966632843\nEpoch 15, Loss: 0.39682071655988693\nEpoch 16, Loss: 0.392195263504982\nEpoch 17, Loss: 0.39070270508527755\nEpoch 18, Loss: 0.3924771651625633\nEpoch 19, Loss: 0.3919020265340805\nEpoch 20, Loss: 0.3908861309289932\ntraining DONE!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Prediction\ndef predict_label(data):\n    model.eval()\n    output = model(data)\n    labels = torch.sigmoid(output).detach().numpy()\n    #predicted_label = 0 if np.mean(labels)<0.1 else 1\n    return labels#predicted_label","metadata":{"execution":{"iopub.status.busy":"2024-06-06T14:44:30.124897Z","iopub.execute_input":"2024-06-06T14:44:30.125795Z","iopub.status.idle":"2024-06-06T14:44:30.130171Z","shell.execute_reply.started":"2024-06-06T14:44:30.125754Z","shell.execute_reply":"2024-06-06T14:44:30.129362Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#to_pyg_list_test([test_graph_sample[0]])\n\ntest_graph_converted = to_pyg_list(test_graph_sample)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T14:44:33.779688Z","iopub.execute_input":"2024-06-06T14:44:33.780041Z","iopub.status.idle":"2024-06-06T14:44:33.819424Z","shell.execute_reply.started":"2024-06-06T14:44:33.780011Z","shell.execute_reply":"2024-06-06T14:44:33.818522Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_graph_converted[:5]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T14:40:18.425603Z","iopub.execute_input":"2024-06-06T14:40:18.426038Z","iopub.status.idle":"2024-06-06T14:40:18.431769Z","shell.execute_reply.started":"2024-06-06T14:40:18.426006Z","shell.execute_reply":"2024-06-06T14:40:18.431030Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"[Data(x=[39, 9], edge_index=[2, 84], edge_attr=[84, 1], y=[3], idx=0),\n Data(x=[46, 9], edge_index=[2, 100], edge_attr=[100, 1], y=[3], idx=1),\n Data(x=[43, 9], edge_index=[2, 100], edge_attr=[100, 1], y=[3], idx=2),\n Data(x=[39, 9], edge_index=[2, 84], edge_attr=[84, 1], y=[3], idx=3),\n Data(x=[42, 9], edge_index=[2, 90], edge_attr=[90, 1], y=[3], idx=4)]"},"metadata":{}}]},{"cell_type":"code","source":"len(test_graph_converted)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T06:46:43.259525Z","iopub.execute_input":"2024-06-06T06:46:43.259867Z","iopub.status.idle":"2024-06-06T06:46:43.264530Z","shell.execute_reply.started":"2024-06-06T06:46:43.259839Z","shell.execute_reply":"2024-06-06T06:46:43.263929Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"60000"},"metadata":{}}]},{"cell_type":"code","source":"# Prediction test\nimport random\nfor i in range(5):\n    print(predict_label(test_graph_converted[i]))","metadata":{"execution":{"iopub.status.busy":"2024-06-06T14:42:37.653888Z","iopub.execute_input":"2024-06-06T14:42:37.654523Z","iopub.status.idle":"2024-06-06T14:42:37.677260Z","shell.execute_reply.started":"2024-06-06T14:42:37.654492Z","shell.execute_reply":"2024-06-06T14:42:37.676298Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"[[0.42482808 0.3352563  0.40486616]]\n[[0.11350316 0.06212707 0.82678086]]\n[[0.15329732 0.09373207 0.78063995]]\n[[0.09917788 0.05173523 0.8439425 ]]\n[[0.4476304 0.3524031 0.3558105]]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Prediction test\nimport random\nfor i in range(5):\n    print(predict_label(test_graph_converted[i]))","metadata":{"execution":{"iopub.status.busy":"2024-06-06T14:45:34.547526Z","iopub.execute_input":"2024-06-06T14:45:34.547862Z","iopub.status.idle":"2024-06-06T14:45:34.571531Z","shell.execute_reply.started":"2024-06-06T14:45:34.547834Z","shell.execute_reply":"2024-06-06T14:45:34.570697Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"[[0.50769645 0.3511258  0.2195074 ]]\n[[0.0588448  0.03147265 0.91117424]]\n[[0.03583939 0.01710124 0.9445825 ]]\n[[0.01836675 0.00760609 0.97094506]]\n[[0.49380073 0.36142725 0.26300958]]\n","output_type":"stream"}]},{"cell_type":"code","source":"list(model.parameters())","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:20:00.937027Z","iopub.execute_input":"2024-06-06T03:20:00.937379Z","iopub.status.idle":"2024-06-06T03:20:00.961421Z","shell.execute_reply.started":"2024-06-06T03:20:00.937349Z","shell.execute_reply":"2024-06-06T03:20:00.960802Z"},"trusted":true},"execution_count":99,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"[Parameter containing:\n tensor([[[ 0.1763, -0.2387, -0.3237, -0.1370, -0.2222,  0.2471, -0.3554,\n           -0.0833,  0.1355],\n          [-0.0458,  0.2860,  0.2351, -0.0527,  0.4113,  0.1894, -0.1312,\n           -0.3435, -0.2739],\n          [ 0.2137,  0.0808,  0.3904, -0.4033,  0.5917,  0.3750,  0.2055,\n            0.0324,  0.3429],\n          [ 0.1209,  0.3231,  0.1468, -0.4594, -0.5316, -0.3590,  0.4509,\n            0.0483, -0.1592],\n          [-0.4331, -0.1767,  0.1458, -0.6204,  0.2631,  0.2888, -0.0221,\n           -0.1666, -0.1359],\n          [-0.5431,  0.0912, -0.3042,  0.3831, -0.2468, -0.5351,  0.4347,\n           -0.1425, -0.1994],\n          [-0.3930,  0.1190,  0.4267,  0.4512,  0.1070, -0.2005,  0.4571,\n           -0.3836, -0.6554],\n          [-0.4865,  0.2638,  0.2727,  0.1475, -0.1508,  0.0932,  0.6952,\n            0.1222,  0.3139],\n          [-0.2323, -0.0626, -0.2128, -0.0150,  0.3152,  0.1406,  0.0223,\n           -0.4397,  0.3480],\n          [-0.4016, -0.3421,  0.4587,  0.3139,  0.5014,  0.3876,  0.1245,\n            0.0530,  0.4052]]], requires_grad=True),\n Parameter containing:\n tensor([[[-0.4012, -0.0081,  0.2185, -0.6203,  0.0112, -0.1880, -0.3501,\n            0.4873,  0.1653],\n          [-0.4593, -0.0939, -0.2082,  0.0529,  0.3115, -0.4125, -0.3880,\n            0.5763, -0.0838],\n          [ 0.3010,  0.4121,  0.2057,  0.2129, -0.4309,  0.1696, -0.4814,\n           -0.3529, -0.4091],\n          [-0.2348,  0.2483, -0.3452, -0.4870, -0.3928,  0.1109,  0.5043,\n            0.4410, -0.5614],\n          [ 0.1751, -0.1717,  0.3098, -0.2402,  0.4626,  0.2023, -0.3244,\n            0.0164, -0.3897],\n          [ 0.1841, -0.5756, -0.3774,  0.0873, -0.4151, -0.4986,  0.3256,\n           -0.0267, -0.0222],\n          [ 0.3911, -0.0243,  0.0426, -0.5665,  0.3488,  0.1212,  0.2379,\n           -0.0162,  0.2556],\n          [-0.1011,  0.5042, -0.1238,  0.2873, -0.2121,  0.4397,  0.0755,\n            0.2800, -0.3365],\n          [-0.1137, -0.4417,  0.1028,  0.4081,  0.3423, -0.2236, -0.0155,\n            0.3916, -0.0240],\n          [ 0.4173,  0.5079, -0.2975, -0.1418,  0.0392,  0.2357, -0.2453,\n            0.4233, -0.5003]]], requires_grad=True),\n Parameter containing:\n tensor([-0.0415, -0.0764, -0.0439, -0.1194, -0.1068, -0.0433,  0.0652,  0.0759,\n         -0.0199,  0.1697,  0.1725,  0.1107, -0.0474, -0.2787, -0.0018, -0.0139,\n         -0.0835,  0.0094, -0.0061, -0.0396, -0.0340, -0.0441, -0.0155, -0.1276,\n         -0.0205, -0.0461, -0.0391, -0.0093, -0.0425,  0.0978, -0.0035,  0.0020,\n         -0.0497,  0.0968, -0.0547, -0.0286, -0.0158, -0.0251, -0.0145, -0.0855,\n          0.0422, -0.0174, -0.0126,  0.0602, -0.1378,  0.0134, -0.0886,  0.0030,\n         -0.0701,  0.0331,  0.0048,  0.1657, -0.0894,  0.0604,  0.0541, -0.1125,\n          0.0616, -0.0890,  0.0058, -0.0628,  0.0420, -0.0471, -0.0145, -0.0453,\n         -0.0252, -0.0631,  0.0116, -0.0906,  0.0551, -0.0782, -0.0385,  0.0566,\n          0.1496, -0.0031, -0.1566, -0.0367, -0.0339,  0.0568, -0.0393,  0.0244,\n         -0.0972,  0.0406,  0.0132,  0.0165,  0.0222,  0.1117, -0.0186,  0.0617,\n         -0.1523, -0.0111], requires_grad=True),\n Parameter containing:\n tensor([[-9.6064e-02,  2.0565e-01,  1.4318e-01, -2.0595e-02,  6.0053e-03,\n           5.1954e-02, -9.2392e-02,  1.6641e-01,  1.0226e-02],\n         [ 2.6119e-01,  5.9672e-02,  1.8931e-01,  1.9635e-01, -1.1419e-01,\n           5.9134e-02,  6.2596e-02, -2.6346e-02,  3.7484e-02],\n         [-6.5793e-04, -2.7474e-01, -1.2245e-01, -8.6827e-02, -1.5121e-01,\n          -2.9907e-03, -1.0078e-01,  2.1110e-01,  2.1098e-01],\n         [ 1.5249e-01,  2.4446e-01, -1.4795e-01, -1.2279e-01, -3.8236e-02,\n           8.9601e-02, -1.0019e-01, -4.0679e-02, -7.4805e-02],\n         [ 1.8453e-01, -1.9655e-01, -1.0260e-01, -1.3500e-01, -1.0863e-01,\n          -1.1393e-01, -1.2448e-01, -1.5702e-01, -5.0288e-02],\n         [-4.9970e-02, -1.1411e-03,  1.2763e-01, -2.1560e-01, -2.5500e-02,\n          -2.8072e-01,  8.3642e-02, -5.4664e-02,  4.9320e-02],\n         [ 1.7116e-01,  6.9182e-02, -2.4246e-01,  4.4231e-03, -1.3178e-01,\n           1.0574e-01, -3.1744e-01, -1.1970e-01, -1.1156e-02],\n         [ 2.6971e-02, -1.6124e-02,  2.1673e-01,  2.5118e-02, -1.2773e-01,\n           1.2778e-01,  1.6326e-01, -1.9593e-01,  6.4471e-02],\n         [-6.3837e-02, -2.1922e-02, -8.2582e-02, -1.2493e-01,  1.6944e-01,\n           2.1373e-01, -3.5647e-02,  1.3085e-01, -2.3989e-01],\n         [-1.4189e-01, -1.8502e-01, -1.4003e-01, -1.5094e-01, -9.1066e-02,\n           4.3241e-02, -1.4855e-01, -1.9232e-01, -1.6123e-01],\n         [-1.7264e-01,  8.3767e-02, -7.6663e-02,  1.3547e-01,  1.3709e-01,\n           1.5165e-01, -3.5472e-02, -9.1717e-02,  2.6113e-01],\n         [ 4.8594e-02, -1.1594e-01,  1.1703e-01, -1.7947e-01,  7.5030e-02,\n           1.2901e-01,  2.6887e-01,  1.9534e-02,  4.8537e-01],\n         [-1.2441e-01,  2.8443e-01, -6.9594e-02, -1.2849e-01, -8.9654e-02,\n          -4.2193e-02, -3.3138e-02, -1.2667e-01, -1.2094e-01],\n         [-2.1502e-01,  2.2402e-01,  2.1512e-01, -1.2410e-01, -1.1587e-01,\n          -1.0015e-01,  1.9353e-02,  1.6188e-03,  1.2448e-01],\n         [ 1.6592e-01,  1.4559e-01, -2.0039e-01, -7.5905e-02, -2.1760e-01,\n          -3.5752e-02,  3.4299e-01,  8.9282e-02,  2.0970e-01],\n         [-4.2638e-02,  2.7031e-03,  2.0871e-01,  1.9324e-01, -2.2267e-01,\n           1.8865e-01, -2.6200e-01,  1.5884e-01,  2.4350e-01],\n         [-1.7546e-01, -1.0997e-01, -1.5016e-01, -5.9356e-02,  1.6563e-01,\n          -2.0127e-01, -2.8182e-01,  2.3755e-01,  2.6198e-02],\n         [ 3.5396e-02,  9.6784e-02,  4.4875e-04, -2.0132e-01, -1.6150e-01,\n          -4.7720e-02,  8.4932e-02,  2.5144e-01, -2.5452e-01],\n         [-1.0077e-01, -1.2019e-01,  1.2129e-01,  1.2790e-01, -2.3941e-02,\n          -6.2949e-02,  2.9149e-01,  1.5494e-01,  3.1441e-01],\n         [ 7.9165e-02,  1.4718e-01,  2.1512e-01,  8.0693e-02,  8.9295e-02,\n           8.1438e-02, -1.7476e-01, -1.1283e-01, -1.9693e-01],\n         [-3.8589e-01,  8.5563e-02, -9.1534e-02,  1.6886e-01,  1.0452e-02,\n          -2.2295e-01, -2.6755e-01,  1.5114e-01,  1.8912e-01],\n         [ 6.2308e-02,  7.4597e-02, -1.3192e-01,  9.5441e-02,  1.4091e-01,\n          -5.6016e-02, -1.5941e-01, -8.3258e-02, -1.0853e-01],\n         [-2.6500e-01,  3.9754e-02, -5.7205e-02, -7.7664e-02,  2.1422e-02,\n          -4.4508e-02, -1.6900e-01, -9.9998e-02,  1.3698e-01],\n         [-3.5726e-01, -1.2396e-01, -1.2594e-02, -6.1028e-02,  1.6661e-01,\n           1.5540e-01, -1.3362e-01,  1.2584e-01, -2.1919e-01],\n         [-2.2491e-01, -1.0764e-02, -7.9104e-02, -1.2566e-01, -1.6334e-01,\n           4.0833e-02,  2.6773e-01,  1.4453e-01, -6.2267e-03],\n         [ 1.7378e-01, -5.8935e-02, -2.3218e-01, -1.5402e-01, -2.3959e-02,\n          -2.0087e-02, -1.4596e-01,  9.5371e-03, -8.3702e-02],\n         [-5.2027e-02, -7.2074e-02,  7.0162e-02, -1.5444e-01, -2.1063e-03,\n           1.6817e-01,  1.1413e-01,  4.8359e-02,  3.0022e-02],\n         [-6.9854e-02, -1.5126e-01, -8.3045e-02, -1.2819e-01, -1.3822e-02,\n           8.4919e-02, -1.1622e-02,  1.0123e-02,  3.3849e-03],\n         [-1.6611e-01, -1.5102e-02,  1.2138e-01, -1.0571e-01,  2.1800e-01,\n           6.4351e-02, -2.8564e-01, -4.2913e-02, -1.4011e-01],\n         [-9.4131e-02,  6.3952e-02, -1.4664e-01, -3.7467e-03,  1.3208e-01,\n           1.6451e-01, -1.0708e-01,  2.6605e-01,  2.0114e-01],\n         [-8.9977e-03,  2.6074e-03,  4.1173e-02,  2.8289e-02,  7.3645e-02,\n          -8.4513e-02,  1.4654e-01, -8.3081e-02, -1.1316e-01],\n         [ 1.0021e-01,  5.0786e-03, -1.6064e-01, -2.3951e-02, -1.7855e-01,\n           1.2240e-01,  1.2319e-01,  2.2977e-01,  1.3364e-01],\n         [-2.2902e-01, -2.8948e-01, -5.9845e-02, -6.3593e-02, -2.0798e-02,\n           1.0996e-01,  1.0241e-01,  2.0740e-02, -1.8608e-01],\n         [-2.9744e-02, -1.6853e-01,  1.5106e-01, -2.3770e-01,  6.6355e-02,\n          -1.7670e-01, -1.5547e-01,  1.4819e-01,  2.1044e-01],\n         [-2.9888e-01,  1.0637e-01,  1.2301e-01, -2.3417e-01,  1.1342e-01,\n           3.7487e-02, -2.7740e-02, -1.0671e-01,  2.5439e-01],\n         [ 2.2601e-02, -1.9188e-01, -2.0543e-02, -1.9886e-01,  6.0507e-02,\n          -2.3267e-01,  2.1829e-01,  4.3238e-02, -2.4670e-01],\n         [ 8.6412e-02, -6.3005e-02, -9.1345e-02, -1.9353e-01,  3.5486e-02,\n           2.0442e-01,  5.0895e-03, -6.8679e-02,  2.1810e-01],\n         [ 2.0622e-01,  2.1960e-01,  1.0298e-01,  1.1595e-01, -2.0286e-01,\n          -1.9020e-01,  9.3284e-02, -1.0990e-01, -2.5214e-01],\n         [ 3.5948e-02,  1.8322e-01, -7.3323e-02,  1.6170e-02, -1.6115e-02,\n          -7.4931e-02, -2.9307e-01, -2.4254e-02, -1.4845e-01],\n         [-1.7044e-01,  5.1095e-02, -1.5488e-01, -9.2600e-02,  1.8468e-01,\n           5.1533e-02, -8.7918e-02,  2.3092e-01,  2.1785e-01],\n         [-2.6228e-02, -9.5964e-02,  1.6928e-01,  1.5101e-01,  1.3179e-01,\n          -2.5013e-01, -6.4614e-02, -1.8506e-01, -1.6765e-01],\n         [ 6.9409e-02,  4.5102e-02, -8.6301e-02,  2.3474e-01,  2.3391e-01,\n          -4.6136e-02, -2.6961e-01, -6.9899e-02,  1.4198e-01],\n         [ 2.3122e-02, -2.2342e-01,  1.7081e-02, -8.2293e-02,  1.1038e-02,\n           1.3785e-01,  1.0574e-01, -1.3423e-01,  2.6413e-01],\n         [-3.5881e-02,  1.7318e-01, -2.3422e-02, -1.3204e-02, -1.4846e-01,\n          -7.8390e-02, -1.2896e-01, -1.1849e-01, -1.3179e-02],\n         [-1.2197e-01, -4.2814e-02, -2.2358e-01, -1.6815e-01,  2.2700e-01,\n           6.9152e-02, -7.4409e-02,  1.8594e-01,  2.0532e-01],\n         [ 2.2080e-01, -1.3925e-01, -2.4419e-01, -1.1786e-01, -2.2345e-01,\n           2.4229e-01, -2.8851e-02, -8.8586e-02, -1.5064e-01],\n         [ 3.1525e-02, -1.5284e-01, -9.1055e-02,  1.5020e-01, -2.1800e-01,\n           5.4092e-03,  1.1222e-01,  7.8386e-02, -9.8520e-02],\n         [ 8.2736e-02,  5.0118e-02, -1.1681e-01,  2.3947e-01, -1.2186e-01,\n           2.2328e-01,  2.1287e-01,  1.9562e-01, -1.4861e-01],\n         [-2.0169e-01, -2.4159e-01,  8.4471e-02,  8.8882e-02, -9.1078e-03,\n          -2.6900e-01, -2.0882e-01,  1.1929e-01, -1.9151e-01],\n         [ 1.4719e-01,  1.6726e-01,  1.7163e-01,  1.1088e-01, -8.7448e-03,\n          -3.5923e-03, -2.1159e-02,  1.4514e-01, -5.2081e-02],\n         [ 2.3738e-01, -1.8052e-01,  2.0575e-01,  7.2363e-02, -2.2273e-01,\n          -1.2886e-01, -5.5452e-02,  1.5800e-01, -9.9313e-02],\n         [-8.2389e-02,  1.5128e-01, -2.1182e-01,  1.1399e-01,  2.2504e-02,\n          -7.2225e-02,  2.4452e-02, -1.6441e-01,  2.9268e-01],\n         [ 2.5861e-02, -2.0456e-01,  2.4089e-01,  4.2923e-02,  1.1237e-01,\n           1.5048e-01,  1.0042e-01,  9.6589e-02,  2.2044e-01],\n         [ 2.6916e-01,  2.0115e-01, -1.2204e-01, -3.0711e-02,  9.4748e-02,\n           2.9214e-01,  1.3366e-01, -1.4269e-01,  7.5979e-02],\n         [-1.8539e-02, -1.6402e-01, -2.1717e-01, -1.9535e-01,  2.3326e-02,\n           3.1900e-02,  2.0429e-02, -5.7395e-02,  6.0297e-02],\n         [-1.3936e-01,  1.0925e-01, -3.5811e-02, -1.9968e-01,  2.2134e-01,\n          -4.0014e-02,  9.2951e-02, -1.2912e-01,  1.0710e-01],\n         [-3.0437e-01, -2.3774e-01, -3.8286e-04, -1.6376e-01,  7.0433e-02,\n           8.6614e-02, -1.4536e-01,  2.0664e-01,  4.3513e-02],\n         [ 1.3063e-01, -1.4472e-01,  1.0952e-01,  2.1333e-01,  1.6640e-01,\n          -1.0534e-01, -1.1682e-01,  2.8117e-01, -2.1048e-01],\n         [ 5.6964e-03, -1.2816e-01, -9.8242e-02,  1.2743e-01,  8.6052e-02,\n          -7.2994e-02, -4.0933e-02, -2.0786e-01,  1.8776e-01],\n         [ 1.9412e-01, -3.9384e-03, -1.7622e-01,  1.7393e-01, -4.3436e-02,\n           3.0209e-03, -2.6034e-01,  1.8980e-01,  1.0855e-01],\n         [-5.7460e-02, -1.0306e-01, -1.5379e-02, -7.2549e-02, -5.8184e-02,\n          -4.2915e-03,  2.8885e-01, -1.1701e-01, -7.3483e-02],\n         [ 1.8531e-01, -1.7313e-01, -1.4278e-01, -2.1900e-01,  1.9661e-01,\n           1.1749e-01, -8.7930e-02,  2.1004e-01, -3.0106e-04],\n         [ 1.9897e-01, -1.2815e-01, -6.6906e-02,  1.0361e-01,  5.1088e-02,\n          -1.1493e-01, -5.3569e-02, -4.1880e-02,  1.4978e-01],\n         [-3.3616e-01, -3.5109e-02,  3.2023e-02, -2.1393e-01, -2.3017e-01,\n          -1.2126e-01,  2.2735e-01,  2.4141e-01,  3.2940e-02],\n         [-2.4256e-02,  1.1563e-01,  1.2596e-01, -1.2919e-01,  8.5620e-02,\n          -1.8473e-01, -2.4438e-01,  1.8244e-01, -5.9886e-02],\n         [-6.2010e-02,  5.9793e-02,  6.2185e-02, -1.4154e-01,  7.5248e-02,\n           1.6130e-01, -8.4665e-02,  1.1767e-01, -1.7223e-02],\n         [ 1.6324e-02,  7.7910e-02,  6.7466e-02, -1.2374e-01, -1.1948e-01,\n          -8.7961e-02, -3.6306e-02,  1.3135e-02, -1.4324e-03],\n         [ 6.0157e-02,  2.2139e-01, -1.8378e-01, -1.1110e-01,  2.0310e-01,\n          -2.3049e-01, -2.6716e-02,  1.0864e-02, -1.0623e-02],\n         [-1.4583e-01,  3.2221e-02,  2.2337e-01,  2.1390e-01, -1.5556e-01,\n          -1.6098e-01, -1.2512e-01,  2.2235e-01, -1.7265e-01],\n         [ 1.5453e-01, -3.4350e-01, -5.5363e-02,  1.3417e-01,  5.2091e-02,\n           1.7951e-01, -1.2543e-01, -5.3295e-02,  2.3362e-01],\n         [ 1.9283e-01,  3.7435e-02, -1.7523e-01, -2.6560e-02,  1.7759e-01,\n          -4.5645e-02,  1.2204e-04, -3.6227e-02,  2.2411e-01],\n         [ 2.3077e-01,  4.9231e-02,  5.5741e-02, -1.7280e-01,  2.0748e-01,\n           3.1145e-01, -1.5343e-01, -4.8614e-02, -6.6410e-02],\n         [-2.2787e-01, -1.7584e-01,  5.9106e-02,  2.5227e-02,  1.0774e-01,\n           2.4065e-01, -1.0336e-01, -2.3573e-02, -1.1521e-01],\n         [ 3.9244e-02,  5.0895e-02, -1.9117e-01, -1.4410e-01,  3.1159e-02,\n           2.3048e-01, -1.8422e-02,  9.6060e-02, -2.7917e-01],\n         [-7.4857e-02, -1.1883e-01,  3.4420e-02,  2.1260e-01,  2.3322e-01,\n           1.4102e-01, -7.2881e-02,  5.9659e-02, -1.7727e-01],\n         [ 1.7066e-01, -8.7442e-02, -5.7706e-04,  2.4406e-02,  2.1263e-01,\n          -1.3484e-01,  1.6280e-01,  1.3743e-01, -1.0316e-01],\n         [ 1.2031e-01, -1.9456e-01,  1.9731e-01,  9.0140e-02, -2.3077e-01,\n          -2.1540e-02, -1.0148e-02,  2.8127e-01, -3.8937e-02],\n         [ 2.3625e-01,  1.8782e-01, -1.3584e-01,  6.6714e-02, -3.7564e-02,\n           4.3220e-02,  1.7826e-01,  1.5312e-01,  3.1555e-01],\n         [ 1.5862e-01,  2.6928e-01, -7.9748e-02, -4.9263e-02, -1.0851e-02,\n           9.4020e-02, -8.4421e-02,  1.0790e-01,  8.5591e-02],\n         [ 6.1107e-02,  9.0217e-02, -1.4661e-01,  8.9668e-02, -1.8810e-01,\n           6.9973e-02, -9.4356e-02,  4.9055e-02, -1.4462e-01],\n         [ 9.2252e-02,  1.3214e-01,  1.9392e-01, -2.3144e-01, -1.3843e-01,\n           4.5060e-03,  2.2357e-01,  2.7770e-01,  6.5795e-02],\n         [ 5.7967e-02,  1.0387e-01, -7.5229e-02,  2.3568e-01,  8.4340e-02,\n          -2.6251e-01,  3.4884e-02,  2.2472e-01, -8.3959e-02],\n         [ 9.5077e-02, -8.3523e-02, -2.0875e-01,  3.3247e-02, -1.5374e-01,\n          -2.5041e-01, -9.5093e-02,  2.1051e-01, -8.7910e-02],\n         [-4.4749e-02, -9.3987e-02,  5.5465e-02,  7.4281e-02, -1.2043e-01,\n          -9.7151e-02,  1.1055e-01, -3.2830e-01, -1.9006e-01],\n         [ 3.3909e-02,  2.3793e-01, -1.4456e-01, -2.2545e-01, -7.4985e-02,\n           2.5078e-02,  1.7472e-01,  1.0056e-01,  3.0900e-01],\n         [ 1.1737e-03, -1.9790e-01,  1.5385e-01, -1.6666e-01,  8.4139e-02,\n           2.1915e-01,  1.7256e-01,  1.1780e-01,  3.8242e-01],\n         [ 8.4175e-02, -2.1748e-01, -3.4256e-03,  1.5370e-01, -1.2615e-01,\n           2.0406e-01,  1.6891e-01, -1.2187e-01,  4.6151e-01],\n         [-1.3496e-01,  4.3873e-02,  1.7255e-01,  6.3687e-02, -2.0345e-01,\n           9.3460e-03,  1.3361e-01, -1.6861e-01, -7.8055e-02],\n         [-6.9168e-02,  8.3226e-02, -1.8521e-01,  6.2572e-02,  3.7527e-02,\n          -1.9920e-01, -9.4839e-02, -1.5053e-01,  2.5440e-01],\n         [-1.4069e-01,  4.6404e-02, -4.0657e-02, -7.4076e-02, -1.0679e-02,\n           2.0366e-01,  2.7085e-02, -2.9308e-01,  5.7578e-02]],\n        requires_grad=True),\n Parameter containing:\n tensor([[[-0.2276, -0.1496, -0.2221,  0.3857, -0.4698,  0.3891, -0.1956,\n           -0.0951, -0.0351,  0.1578,  0.1536, -0.3187, -0.1905, -0.0552,\n           -0.2938, -0.0209, -0.5399,  0.4409, -0.2670,  0.1074, -0.2082,\n           -0.2372,  0.3596, -0.2819,  0.1974, -0.2003, -0.3450,  0.3108,\n           -0.0060, -0.1763,  0.1059,  0.0726]]], requires_grad=True),\n Parameter containing:\n tensor([[[ 0.0517,  0.3915, -0.1501,  0.3501,  0.4333,  0.1490,  0.1081,\n           -0.0919,  0.0879,  0.2903, -0.1399,  0.0508,  0.1787, -0.0604,\n            0.0663, -0.1540,  0.1123,  0.2119,  0.1613, -0.2561, -0.1473,\n           -0.3237, -0.3505, -0.4779, -0.1087,  0.3546, -0.1107, -0.2343,\n            0.0347,  0.2319, -0.2057, -0.1013]]], requires_grad=True),\n Parameter containing:\n tensor([ 4.8556e-06, -5.9206e-05, -1.1261e-05, -2.7367e-05,  2.6658e-05,\n         -2.0151e-05,  2.4756e-05,  1.0169e-04,  2.4919e-05, -2.3386e-05,\n         -6.9073e-06, -2.0382e-05, -4.7191e-06,  1.1064e-04, -4.0861e-05,\n          5.0902e-05,  6.1591e-06, -2.4851e-06,  2.0377e-06, -5.3532e-05,\n         -3.2778e-08, -5.6497e-07,  1.3550e-05, -1.3702e-05,  4.4887e-05,\n         -5.6131e-06, -1.7507e-05, -6.1816e-05,  6.5453e-06, -1.6893e-05,\n          4.0693e-05, -1.3624e-05], requires_grad=True),\n Parameter containing:\n tensor([[ 0.2039,  0.0751, -0.0599,  ...,  0.0029, -0.2478, -0.0552],\n         [ 0.1075, -0.2210,  0.0067,  ..., -0.1969, -0.1823, -0.1042],\n         [-0.1402,  0.0562, -0.0206,  ...,  0.0203, -0.0144, -0.0358],\n         ...,\n         [ 0.0190,  0.2566,  0.0534,  ..., -0.0700,  0.0027,  0.1364],\n         [-0.1947,  0.0554, -0.0837,  ...,  0.1053, -0.1166,  0.1094],\n         [ 0.0189,  0.1413, -0.0007,  ...,  0.1128, -0.0872,  0.0457]],\n        requires_grad=True),\n Parameter containing:\n tensor([[ 0.1190, -0.0771,  0.0047,  ..., -0.1655, -0.0996, -0.0425],\n         [-0.1733, -0.1436,  0.0954,  ..., -0.1428,  0.1376,  0.0508],\n         [ 0.1164,  0.1591, -0.1812,  ..., -0.0889,  0.0508,  0.0319],\n         ...,\n         [ 0.1653, -0.0924,  0.1144,  ..., -0.1390, -0.0188,  0.0186],\n         [-0.1249, -0.1128, -0.0375,  ...,  0.0700,  0.0290,  0.0792],\n         [ 0.0527,  0.1239,  0.0550,  ..., -0.1523, -0.0875,  0.0694]],\n        requires_grad=True),\n Parameter containing:\n tensor([ 0.1173, -0.0051, -0.1093,  0.1498, -0.1117,  0.1433,  0.0205,  0.1319,\n         -0.0604, -0.0336, -0.1200,  0.1303, -0.0195, -0.1025, -0.1525,  0.0269,\n          0.0708, -0.1045,  0.0382,  0.0356,  0.0854, -0.0864, -0.0731, -0.1095,\n          0.0499,  0.1561,  0.0079, -0.0188,  0.0249, -0.1637, -0.1120,  0.1140],\n        requires_grad=True),\n Parameter containing:\n tensor([0.8552, 0.9492, 0.9114, 0.8941, 0.9789, 0.9786, 0.8945, 0.9992, 0.9475,\n         0.9063, 0.9742, 0.9369, 0.6602, 0.9703, 0.9209, 0.9493, 0.9148, 0.9487,\n         0.9763, 0.9989, 0.9123, 1.0023, 0.9822, 0.7828, 0.9365, 0.9325, 0.8963,\n         1.0095, 0.8606, 0.9069, 0.9616, 0.9738], requires_grad=True),\n Parameter containing:\n tensor([-0.1532, -0.0645, -0.0985, -0.1665, -0.0343, -0.0515, -0.1098, -0.0216,\n         -0.0303, -0.0933, -0.0173, -0.0800, -0.3227, -0.0715, -0.0954, -0.0659,\n         -0.1054, -0.0475, -0.0405,  0.0116, -0.0922, -0.0046, -0.0502, -0.2251,\n         -0.0494, -0.0974, -0.1281, -0.0353, -0.1263, -0.1234, -0.0292, -0.0401],\n        requires_grad=True),\n Parameter containing:\n tensor([[-0.0101, -0.1698, -0.0614,  ...,  0.0431, -0.1549, -0.1108],\n         [ 0.1337,  0.1684,  0.0872,  ...,  0.1482, -0.1646,  0.1674],\n         [-0.0877, -0.0011,  0.1099,  ..., -0.0169,  0.0589,  0.0856],\n         ...,\n         [ 0.0718,  0.0316,  0.1104,  ...,  0.0286, -0.1417, -0.1922],\n         [ 0.0822, -0.0167,  0.0535,  ..., -0.0661,  0.0875,  0.0056],\n         [-0.0574, -0.0203, -0.0343,  ...,  0.0530, -0.0229,  0.1797]],\n        requires_grad=True),\n Parameter containing:\n tensor([ 0.1460,  0.2198,  0.0659, -0.0627, -0.0480, -0.0988, -0.0684,  0.1462,\n          0.0293, -0.0158, -0.0393, -0.0537, -0.1203, -0.0035, -0.1949,  0.1190,\n          0.2781,  0.1815,  0.1093,  0.1438,  0.0880,  0.0963, -0.1010,  0.0789,\n         -0.0384, -0.0441,  0.0841, -0.0889,  0.1998,  0.1616,  0.1063, -0.1881,\n         -0.1063, -0.1242,  0.1902, -0.0754,  0.1034, -0.0055,  0.1990,  0.1073,\n         -0.1388, -0.1358,  0.0706,  0.1054,  0.0460, -0.1839,  0.0664, -0.0787,\n         -0.0282, -0.0735, -0.0277,  0.0696, -0.0998,  0.1283, -0.0767, -0.0550,\n          0.0498, -0.1130,  0.1307,  0.0385, -0.1455,  0.0722, -0.1624, -0.0912],\n        requires_grad=True),\n Parameter containing:\n tensor([[ 0.0476, -0.1138,  0.0178,  ...,  0.0994,  0.1079,  0.0063],\n         [-0.1220, -0.0258, -0.1218,  ..., -0.1072, -0.0136,  0.0243],\n         [-0.1622,  0.0333, -0.0510,  ..., -0.1306, -0.0699,  0.0422],\n         ...,\n         [-0.0328, -0.0700,  0.0036,  ..., -0.0639,  0.0190, -0.0314],\n         [ 0.1724,  0.1458,  0.0455,  ..., -0.0251, -0.0458, -0.0932],\n         [ 0.1367,  0.0487,  0.1272,  ..., -0.0015,  0.0764,  0.0625]],\n        requires_grad=True),\n Parameter containing:\n tensor([ 0.0548, -0.0431, -0.0485,  0.1340,  0.1605,  0.0641,  0.1216,  0.0973,\n          0.1748,  0.2850,  0.2876,  0.2547,  0.0015,  0.1901, -0.1713, -0.1105,\n          0.2079,  0.0861,  0.0998,  0.1555,  0.2730,  0.0810,  0.1719,  0.1005,\n          0.0300, -0.1683,  0.0319,  0.2318,  0.2304,  0.2243,  0.1777,  0.0897],\n        requires_grad=True),\n Parameter containing:\n tensor([[ 0.1243, -0.2043,  0.1324, -0.1104, -0.1132,  0.0004, -0.1415, -0.1554,\n          -0.1240, -0.1630, -0.1291, -0.1139, -0.2311, -0.1518, -0.1756,  0.0701,\n          -0.0214,  0.0141, -0.0718, -0.1299, -0.1088, -0.1170, -0.1571, -0.1620,\n           0.0972, -0.1051,  0.0245, -0.1120, -0.0992, -0.2113, -0.1134, -0.1259],\n         [-0.1119, -0.0500,  0.0498, -0.1433, -0.1696, -0.2563, -0.1246, -0.1323,\n          -0.1207, -0.0897, -0.1388, -0.1104, -0.2336, -0.1303, -0.0013,  0.0140,\n          -0.1091,  0.1116, -0.2243, -0.1056, -0.1520, -0.0595, -0.1922, -0.1100,\n           0.1036, -0.0927, -0.0421, -0.0907, -0.0966, -0.0890, -0.1618, -0.1543],\n         [-0.0343, -0.1230,  0.1164, -0.0256,  0.1183,  0.0122,  0.0547,  0.1253,\n           0.0666,  0.0549,  0.1066,  0.0445, -0.0294,  0.1049, -0.0618, -0.1092,\n           0.0221,  0.1059,  0.0546,  0.1162,  0.0599,  0.0607,  0.1184,  0.1061,\n           0.0067,  0.1027,  0.2144,  0.0686,  0.0222,  0.1473,  0.0923,  0.1041]],\n        requires_grad=True),\n Parameter containing:\n tensor([-0.4730, -0.2670,  0.3911], requires_grad=True)]"},"metadata":{}}]},{"cell_type":"code","source":"#Debug code end","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create sample training_set of torch_geometric.data objects\ntraining_set = train_graph#[Data(idx=-1, edge_index=None, x=torch.rand(5, 20), edge_attr=None, y=torch.tensor([0, 0, 1])) for _ in range(10)]\n\n# Train with the training_set\ntrain_model(training_set)\nprint('training DONE!')","metadata":{"execution":{"iopub.status.busy":"2024-06-06T02:34:55.740957Z","iopub.execute_input":"2024-06-06T02:34:55.741762Z","iopub.status.idle":"2024-06-06T02:46:20.412152Z","shell.execute_reply.started":"2024-06-06T02:34:55.741724Z","shell.execute_reply":"2024-06-06T02:46:20.411023Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"training DONE!\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('testset: ',len(test_graph_sample),len(test_bind_sample))","metadata":{"execution":{"iopub.status.busy":"2024-06-06T02:48:45.101718Z","iopub.execute_input":"2024-06-06T02:48:45.102337Z","iopub.status.idle":"2024-06-06T02:48:45.107220Z","shell.execute_reply.started":"2024-06-06T02:48:45.102303Z","shell.execute_reply":"2024-06-06T02:48:45.106382Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"testset:  60000 60000\n","output_type":"stream"}]},{"cell_type":"code","source":"# Prediction test\n\npredict_label(to_pyg_list_test([test_graph_sample[1]])[0])","metadata":{"execution":{"iopub.status.busy":"2024-06-06T02:50:07.752788Z","iopub.execute_input":"2024-06-06T02:50:07.753170Z","iopub.status.idle":"2024-06-06T02:50:07.767470Z","shell.execute_reply.started":"2024-06-06T02:50:07.753137Z","shell.execute_reply":"2024-06-06T02:50:07.766207Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 1604.55it/s]\n","output_type":"stream"},{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"array([[1.7834864e-10, 1.7490207e-10, 1.8219261e-10]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"#to_pyg_list_test([test_graph_sample[0]])\n\ntest_graph_converted = to_pyg_list(test_graph_sample)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T06:45:35.912142Z","iopub.execute_input":"2024-06-06T06:45:35.912506Z","iopub.status.idle":"2024-06-06T06:45:47.388917Z","shell.execute_reply.started":"2024-06-06T06:45:35.912475Z","shell.execute_reply":"2024-06-06T06:45:47.388160Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"100%|██████████| 60000/60000 [00:11<00:00, 5230.79it/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"pred = []\nfor i in test_graph_converted:\n    pred.append(predict_label(i))\nprint('prediction DONE!')","metadata":{"execution":{"iopub.status.busy":"2024-06-04T06:46:31.115419Z","iopub.execute_input":"2024-06-04T06:46:31.116150Z","iopub.status.idle":"2024-06-04T06:49:01.890995Z","shell.execute_reply.started":"2024-06-04T06:46:31.116113Z","shell.execute_reply":"2024-06-04T06:49:01.890134Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"prediction DONE!\n","output_type":"stream"}]},{"cell_type":"code","source":"print(test_graph_converted[0])\nprint(test_graph_converted[1])\nprint(test_graph_converted[2])","metadata":{"execution":{"iopub.status.busy":"2024-06-04T06:51:02.496696Z","iopub.execute_input":"2024-06-04T06:51:02.497108Z","iopub.status.idle":"2024-06-04T06:51:02.501796Z","shell.execute_reply.started":"2024-06-04T06:51:02.497078Z","shell.execute_reply":"2024-06-04T06:51:02.501032Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Data(x=[38, 9], edge_index=[2, 84], edge_attr=[84, 1], y=[3], idx=0)\nData(x=[38, 9], edge_index=[2, 82], edge_attr=[82, 1], y=[3], idx=1)\nData(x=[40, 9], edge_index=[2, 84], edge_attr=[84, 1], y=[3], idx=2)\n","output_type":"stream"}]},{"cell_type":"code","source":"predict_label(test_graph_converted[0])\npredict_label(test_graph_converted[50000])\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T07:24:14.679713Z","iopub.execute_input":"2024-06-04T07:24:14.680574Z","iopub.status.idle":"2024-06-04T07:24:14.692485Z","shell.execute_reply.started":"2024-06-04T07:24:14.680537Z","shell.execute_reply":"2024-06-04T07:24:14.691672Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"array([[3.1234331e-06, 4.9364104e-07, 1.3663475e-03]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"pred[:10]","metadata":{"execution":{"iopub.status.busy":"2024-06-04T06:49:57.295973Z","iopub.execute_input":"2024-06-04T06:49:57.296326Z","iopub.status.idle":"2024-06-04T06:49:57.304257Z","shell.execute_reply.started":"2024-06-04T06:49:57.296298Z","shell.execute_reply":"2024-06-04T06:49:57.303355Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"[array([[1.7716570e-10, 1.7484734e-10, 1.8214014e-10]], dtype=float32),\n array([[1.7716570e-10, 1.7484734e-10, 1.8214014e-10]], dtype=float32),\n array([[1.7716570e-10, 1.7484734e-10, 1.8214014e-10]], dtype=float32),\n array([[1.7716570e-10, 1.7484734e-10, 1.8214014e-10]], dtype=float32),\n array([[1.7716570e-10, 1.7484734e-10, 1.8214014e-10]], dtype=float32),\n array([[1.7716570e-10, 1.7484734e-10, 1.8214014e-10]], dtype=float32),\n array([[1.7716570e-10, 1.7484734e-10, 1.8214014e-10]], dtype=float32),\n array([[1.7716570e-10, 1.7484734e-10, 1.8214014e-10]], dtype=float32),\n array([[1.7716570e-10, 1.7484734e-10, 1.8214014e-10]], dtype=float32),\n array([[1.7716570e-10, 1.7484734e-10, 1.8214014e-10]], dtype=float32)]"},"metadata":{}}]},{"cell_type":"code","source":"test_bind_sample[:5]\n\ntest_bind_sample1d = []\n\nfor i in test_bind_sample:\n    if sum(i)>=1:\n        test_bind_sample1d.append(1)\n    else:\n        test_bind_sample1d.append(0)\nprint('DONE!')","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:03:41.979045Z","iopub.execute_input":"2024-06-03T09:03:41.979938Z","iopub.status.idle":"2024-06-03T09:03:42.223365Z","shell.execute_reply.started":"2024-06-03T09:03:41.979899Z","shell.execute_reply":"2024-06-03T09:03:42.222351Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"DONE!\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(pred),len(test_bind_sample1d))","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:03:44.679612Z","iopub.execute_input":"2024-06-03T09:03:44.680036Z","iopub.status.idle":"2024-06-03T09:03:44.685437Z","shell.execute_reply.started":"2024-06-03T09:03:44.680000Z","shell.execute_reply":"2024-06-03T09:03:44.684444Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"60000 60000\n","output_type":"stream"}]},{"cell_type":"code","source":"res = []\nfor i in range(len(pred)):\n    if pred[i] == test_bind_sample1d[i]:\n        res.append(1)\n    else:\n        res.append(0)\n        \nprint(np.mean(res))        ","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:03:47.346132Z","iopub.execute_input":"2024-06-03T09:03:47.346510Z","iopub.status.idle":"2024-06-03T09:03:47.368932Z","shell.execute_reply.started":"2024-06-03T09:03:47.346477Z","shell.execute_reply":"2024-06-03T09:03:47.368210Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"0.5\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len([x for x in pred if x ==0]))","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:03:59.679515Z","iopub.execute_input":"2024-06-03T09:03:59.679899Z","iopub.status.idle":"2024-06-03T09:03:59.687419Z","shell.execute_reply.started":"2024-06-03T09:03:59.679868Z","shell.execute_reply":"2024-06-03T09:03:59.686783Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"60000\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Graph NN Code Repo","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nimport rdkit\nfrom rdkit import Chem\n\nimport torch\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\n\nfrom torch_geometric.nn import MessagePassing, global_mean_pool\nfrom torch_scatter import scatter\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nprint('import ok!')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# helper\n# torch version of np unpackbits\n#https://gist.github.com/vadimkantorov/30ea6d278bc492abf6ad328c6965613a\n\ndef tensor_dim_slice(tensor, dim, dim_slice):\n\treturn tensor[(dim if dim >= 0 else dim + tensor.dim()) * (slice(None),) + (dim_slice,)]\n\n# @torch.jit.script\ndef packshape(shape, dim: int = -1, mask: int = 0b00000001, dtype=torch.uint8, pack=True):\n\tdim = dim if dim >= 0 else dim + len(shape)\n\tbits, nibble = (\n\t\t8 if dtype is torch.uint8 else 16 if dtype is torch.int16 else 32 if dtype is torch.int32 else 64 if dtype is torch.int64 else 0), (\n\t\t1 if mask == 0b00000001 else 2 if mask == 0b00000011 else 4 if mask == 0b00001111 else 8 if mask == 0b11111111 else 0)\n\t# bits = torch.iinfo(dtype).bits # does not JIT compile\n\tassert nibble <= bits and bits % nibble == 0\n\tnibbles = bits // nibble\n\tshape = (shape[:dim] + (int(math.ceil(shape[dim] / nibbles)),) + shape[1 + dim:]) if pack else (\n\t\t\t\tshape[:dim] + (shape[dim] * nibbles,) + shape[1 + dim:])\n\treturn shape, nibbles, nibble\n\n# @torch.jit.script\ndef F_unpackbits(tensor, dim: int = -1, mask: int = 0b00000001, shape=None, out=None, dtype=torch.uint8):\n\tdim = dim if dim >= 0 else dim + tensor.dim()\n\tshape_, nibbles, nibble = packshape(tensor.shape, dim=dim, mask=mask, dtype=tensor.dtype, pack=False)\n\tshape = shape if shape is not None else shape_\n\tout = out if out is not None else torch.empty(shape, device=tensor.device, dtype=dtype)\n\tassert out.shape == shape\n\n\tif shape[dim] % nibbles == 0:\n\t\tshift = torch.arange((nibbles - 1) * nibble, -1, -nibble, dtype=torch.uint8, device=tensor.device)\n\t\tshift = shift.view(nibbles, *((1,) * (tensor.dim() - dim - 1)))\n\t\treturn torch.bitwise_and((tensor.unsqueeze(1 + dim) >> shift).view_as(out), mask, out=out)\n\n\telse:\n\t\tfor i in range(nibbles):\n\t\t\tshift = nibble * i\n\t\t\tsliced_output = tensor_dim_slice(out, dim, slice(i, None, nibbles))\n\t\t\tsliced_input = tensor.narrow(dim, 0, sliced_output.shape[dim])\n\t\t\ttorch.bitwise_and(sliced_input >> shift, mask, out=sliced_output)\n\treturn out\n\nclass dotdict(dict):\n\t__setattr__ = dict.__setitem__\n\t__delattr__ = dict.__delitem__\n\t\n\tdef __getattr__(self, name):\n\t\ttry:\n\t\t\treturn self[name]\n\t\texcept KeyError:\n\t\t\traise AttributeError(name)\n\n            \nprint('helper ok!')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mol to graph adopted from\n# from https://github.com/LiZhang30/GPCNDTA/blob/main/utils/DrugGraph.py\n\nPACK_NODE_DIM=9\nPACK_EDGE_DIM=1\nNODE_DIM=PACK_NODE_DIM*8\nEDGE_DIM=PACK_EDGE_DIM*8\n\ndef one_of_k_encoding(x, allowable_set, allow_unk=False):\n\tif x not in allowable_set:\n\t\tif allow_unk:\n\t\t\tx = allowable_set[-1]\n\t\telse:\n\t\t\traise Exception(f'input {x} not in allowable set{allowable_set}!!!')\n\treturn list(map(lambda s: x == s, allowable_set))\n\n\n#Get features of an atom (one-hot encoding:)\n'''\n\t1.atom element: 44+1 dimensions    \n\t2.the atom's hybridization: 5 dimensions\n\t3.degree of atom: 6 dimensions                        \n\t4.total number of H bound to atom: 6 dimensions\n\t5.number of implicit H bound to atom: 6 dimensions    \n\t6.whether the atom is on ring: 1 dimension\n\t7.whether the atom is aromatic: 1 dimension           \n\tTotal: 70 dimensions\n'''\n\nATOM_SYMBOL = [\n\t'C', 'N', 'O', 'S', 'F', 'Si', 'P', 'Cl', 'Br', 'Mg',\n\t'Na', 'Ca', 'Fe', 'As', 'Al', 'I', 'B', 'V', 'K', 'Tl',\n\t'Yb', 'Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se', 'Ti', 'Zn', 'H',\n\t'Li', 'Ge', 'Cu', 'Au', 'Ni', 'Cd', 'In', 'Mn', 'Zr', 'Cr',\n\t'Pt', 'Hg', 'Pb', 'Dy',\n\t#'Unknown'\n]\n#print('ATOM_SYMBOL', len(ATOM_SYMBOL))44\nHYBRIDIZATION_TYPE = [\n\tChem.rdchem.HybridizationType.S,\n\tChem.rdchem.HybridizationType.SP,\n\tChem.rdchem.HybridizationType.SP2,\n\tChem.rdchem.HybridizationType.SP3,\n\tChem.rdchem.HybridizationType.SP3D\n]\n\ndef get_atom_feature(atom):\n\tfeature = (\n\t\t one_of_k_encoding(atom.GetSymbol(), ATOM_SYMBOL)\n\t   + one_of_k_encoding(atom.GetHybridization(), HYBRIDIZATION_TYPE)\n\t   + one_of_k_encoding(atom.GetDegree(), [0, 1, 2, 3, 4, 5])\n\t   + one_of_k_encoding(atom.GetTotalNumHs(), [0, 1, 2, 3, 4, 5])\n\t   + one_of_k_encoding(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5])\n\t   + [atom.IsInRing()]\n\t   + [atom.GetIsAromatic()]\n\t)\n\t#feature = np.array(feature, dtype=np.uint8)\n\tfeature = np.packbits(feature)\n\treturn feature\n\n\n#Get features of an edge (one-hot encoding)\n'''\n\t1.single/double/triple/aromatic: 4 dimensions       \n\t2.the atom's hybridization: 1 dimensions\n\t3.whether the bond is on ring: 1 dimension          \n\tTotal: 6 dimensions\n'''\n\ndef get_bond_feature(bond):\n\tbond_type = bond.GetBondType()\n\tfeature = [\n\t\tbond_type == Chem.rdchem.BondType.SINGLE,\n\t\tbond_type == Chem.rdchem.BondType.DOUBLE,\n\t\tbond_type == Chem.rdchem.BondType.TRIPLE,\n\t\tbond_type == Chem.rdchem.BondType.AROMATIC,\n\t\tbond.GetIsConjugated(),\n\t\tbond.IsInRing()\n\t]\n\t#feature = np.array(feature, dtype=np.uint8)\n\tfeature = np.packbits(feature)\n\treturn feature\n\n\ndef smile_to_graph(smiles):\n\tmol = Chem.MolFromSmiles(smiles)\n\tN = mol.GetNumAtoms()\n\tnode_feature = []\n\tedge_feature = []\n\tedge = []\n\tfor i in range(mol.GetNumAtoms()):\n\t\tatom_i = mol.GetAtomWithIdx(i)\n\t\tatom_i_features = get_atom_feature(atom_i)\n\t\tnode_feature.append(atom_i_features)\n\n\t\tfor j in range(mol.GetNumAtoms()):\n\t\t\tbond_ij = mol.GetBondBetweenAtoms(i, j)\n\t\t\tif bond_ij is not None:\n\t\t\t\tedge.append([i, j])\n\t\t\t\tbond_features_ij = get_bond_feature(bond_ij)\n\t\t\t\tedge_feature.append(bond_features_ij)\n\tnode_feature=np.stack(node_feature)\n\tedge_feature=np.stack(edge_feature)\n\tedge = np.array(edge,dtype=np.uint8)\n\treturn N,edge,node_feature,edge_feature\n\ndef to_pyg_format(N,edge,node_feature,edge_feature):\n\tgraph = Data(\n\t\tidx=-1,\n\t\tedge_index = torch.from_numpy(edge.T).int(),\n\t\tx          = torch.from_numpy(node_feature).byte(),\n\t\tedge_attr  = torch.from_numpy(edge_feature).byte(),\n\t)\n\treturn graph\n\n#debug one example\ng = to_pyg_format(*smile_to_graph(smiles=\"C#CCOc1ccc(CNc2nc(NCc3cccc(Br)n3)nc(N[C@@H](CC#C)CC(=O)NC)n2)cc1\"))\nprint(g)\nprint('[Dy] is replaced by C !!')\nprint('smile_to_graph() ok!')","metadata":{"execution":{"iopub.status.busy":"2024-05-29T06:53:02.452061Z","iopub.execute_input":"2024-05-29T06:53:02.452583Z","iopub.status.idle":"2024-05-29T06:53:02.510427Z","shell.execute_reply.started":"2024-05-29T06:53:02.452550Z","shell.execute_reply":"2024-05-29T06:53:02.508128Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('DONE')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nimport rdkit\nfrom rdkit import Chem\n\nimport torch\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\n\nfrom torch_geometric.nn import MessagePassing, global_mean_pool\nfrom torch_scatter import scatter\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nprint('import ok!')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install rdkit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE='cpu'\n\n# i have removed all comments here to jepp it clean. refer to orginal link for code comments\n# of MPNNModel\nclass MPNNLayer(MessagePassing):\n\tdef __init__(self, emb_dim=64, edge_dim=4, aggr='add'):\n\t\tsuper().__init__(aggr=aggr)\n\n\t\tself.emb_dim = emb_dim\n\t\tself.edge_dim = edge_dim\n\t\tself.mlp_msg = nn.Sequential(\n\t\t\tnn.Linear(2 * emb_dim + edge_dim, emb_dim), nn.BatchNorm1d(emb_dim), nn.ReLU(),\n\t\t\tnn.Linear(emb_dim, emb_dim), nn.BatchNorm1d(emb_dim), nn.ReLU()\n\t\t)\n\t\tself.mlp_upd = nn.Sequential(\n\t\t\tnn.Linear(2 * emb_dim, emb_dim), nn.BatchNorm1d(emb_dim), nn.ReLU(),\n\t\t\tnn.Linear(emb_dim, emb_dim), nn.BatchNorm1d(emb_dim), nn.ReLU()\n\t\t)\n\n\tdef forward(self, h, edge_index, edge_attr):\n\t\tout = self.propagate(edge_index, h=h, edge_attr=edge_attr)\n\t\treturn out\n\n\tdef message(self, h_i, h_j, edge_attr):\n\t\tmsg = torch.cat([h_i, h_j, edge_attr], dim=-1)\n\t\treturn self.mlp_msg(msg)\n\n\tdef aggregate(self, inputs, index):\n\t\treturn scatter(inputs, index, dim=self.node_dim, reduce=self.aggr)\n\n\tdef update(self, aggr_out, h):\n\t\tupd_out = torch.cat([h, aggr_out], dim=-1)\n\t\treturn self.mlp_upd(upd_out)\n\n\tdef __repr__(self) -> str:\n\t\treturn (f'{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})')\n\n\nclass MPNNModel(nn.Module):\n    def __init__(self, num_layers=3, emb_dim=64, in_dim=11, edge_dim=4, out_dim=1):\n        super().__init__()\n\n        self.lin_in = nn.Linear(in_dim, emb_dim)\n\n        # Stack of MPNN layers\n        self.convs = torch.nn.ModuleList()\n        for layer in range(num_layers):\n            self.convs.append(MPNNLayer(emb_dim, edge_dim, aggr='add'))\n\n        self.pool = global_mean_pool\n\n    def forward(self, data): #PyG.Data - batch of PyG graphs\n\n        h = self.lin_in(F_unpackbits(data.x,-1).float())  \n\n        for conv in self.convs:\n            h = h + conv(h, data.edge_index.long(), F_unpackbits(data.edge_attr,-1).float())  # (n, d) -> (n, d)\n\n        h_graph = self.pool(h, data.batch)  \n        return h_graph\n\n# our prediction model here !!!!\nclass Net(nn.Module):\n    def __init__(self, ):\n        super().__init__()\n\n        self.output_type = ['infer', 'loss']\n\n        graph_dim=96\n        self.smile_encoder = MPNNModel(\n            in_dim=NODE_DIM, edge_dim=EDGE_DIM, emb_dim=graph_dim, num_layers=4,\n        )\n        self.bind = nn.Sequential(\n            nn.Linear(graph_dim, 1024),\n            #nn.BatchNorm1d(1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.1),\n            nn.Linear(1024, 1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.1),\n            nn.Linear(1024, 512),\n            #nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.1),\n            nn.Linear(512, 3),\n        )\n\n    def forward(self, batch):\n        graph = batch['graph']\n        x = self.smile_encoder(graph) \n        bind = self.bind(x)\n\n        # --------------------------\n        output = {}\n        if 'loss' in self.output_type:\n            target = batch['bind']\n            output['bce_loss'] = F.binary_cross_entropy_with_logits(bind.float(), target.float())\n        if 'infer' in self.output_type:\n            output['bind'] = torch.sigmoid(bind)\n\n        return output\n    \nprint('Create Model OK!')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#debug: make some dummy data and run\n\ndef run_check_net():\n\tbatch_size = 3\n\tnode_dim=NODE_DIM\n\tedge_dim=EDGE_DIM\n\n\tdata = []\n\tfor b in range(batch_size):\n\t\tN = np.random.randint(5,10)\n\t\tE = np.random.randint(3,N*(N-1))\n\t\tedge_index = np.stack([\n\t\t\tnp.random.choice(N, E, replace=True),\n\t\t\tnp.random.choice(N, E, replace=True),\n\t\t]).T\n\t\tedge_index = np.sort(edge_index)\n\t\tedge_index = edge_index[edge_index[:, 0].argsort()]\n\t\tedge_index[0] = [0,1] #default\n\t\tedge_index = edge_index[edge_index[:,0]!=edge_index[:,1]]\n\t\tedge_index = np.unique(edge_index, axis=0)\n\n\t\tE = len(edge_index)\n\t\tedge_index = np.ascontiguousarray(edge_index.T)\n\n\t\td = Data(\n\t\t\tidx        = b,\n\t\t\tedge_index = torch.from_numpy(edge_index).int(),\n\t\t\tx          = torch.from_numpy(np.packbits(np.random.choice(2, (N, node_dim)),-1)).byte(),\n\t\t\tedge_attr  = torch.from_numpy(np.packbits(np.random.choice(2, (E, edge_dim)),-1)).byte(),\n\t\t)\n\t\tdata.append(d)\n\n\t#from my_mol2graph import make_dummy_data\n\t#data = make_dummy_data()\n\n\tloader = DataLoader(data, batch_size=batch_size)\n\tgraph = next(iter(loader))\n\tidx = graph.idx.tolist()  #use to index bind array\n\tbatch = dotdict( \n\t\tgraph = graph.to(DEVICE),\n\t\tbind  = torch.from_numpy(np.random.choice(2, (batch_size, 3))).float().to(DEVICE),\n\t)\n\tzz=0\n \n\tnet = Net().to(DEVICE)\n\t#print(net)\n\n\twith torch.no_grad():\n\t\twith torch.cuda.amp.autocast(enabled=True): # dtype=torch.float16):\n\t\t\toutput = net(batch)\n\t\t\t#print(output['bind'])\n\n\t# ---\n\tprint('batch')\n\tfor k, v in batch.items():\n\t\tif k=='idx':\n\t\t\tprint(f'{k:>32} : {len(v)} ')\n\t\telif k=='graph':\n\t\t\tprint(f'{k:>32} : {graph} ')\n\t\telse:\n\t\t\tprint(f'{k:>32} : {v.shape} ')\n\n\tprint('output')\n\tfor k, v in output.items():\n\t\tif 'loss' not in k:\n\t\t\tprint(f'{k:>32} : {v.shape} ')\n\tprint('loss')\n\tfor k, v in output.items():\n\t\tif 'loss' in k:\n\t\t\tprint(f'{k:>32} : {v.item()} ')\n\n            \nrun_check_net()\nprint('model ok!')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def my_collate(graph, index=None, device='cpu'):\n    if index is None:\n        index = np.arange(len(graph)).tolist()\n    batch = dotdict(\n        x=[],\n        edge_index=[],\n        edge_attr=[],\n        batch=[],\n        idx=index\n    )\n    offset = 0\n    for b, i in enumerate(index):\n        N, edge, node_feature, edge_feature = graph[i]\n        batch.x.append(node_feature)\n        batch.edge_attr.append(edge_feature)\n        batch.edge_index.append(edge.astype(int) + offset)\n        batch.batch += N * [b]\n        offset += N\n    batch.x = torch.from_numpy(np.concatenate(batch.x)).to(device)\n    batch.edge_attr = torch.from_numpy(np.concatenate(batch.edge_attr)).to(device)\n    batch.edge_index = torch.from_numpy(np.concatenate(batch.edge_index).T).to(device)\n    batch.batch = torch.LongTensor(batch.batch).to(device)\n    return batch\n\n\n#.... more code here ....\n\nwhile epoch<cfg.num_epoch:\n    shuffled_idx = train_idx.copy()\n    np.random.shuffle(shuffled_idx)\n    for t, index in enumerate(np.arange(0,len(shuffled_idx),cfg.train_batch_size)):\n        index = shuffled_idx[index:index+cfg.train_batch_size]\n        if len(index)!=cfg.train_batch_size: continue #drop last\n\n        B = len(index)\n        batch = dotdict(\n            graph = my_collate(train_graph,index,device='cuda'),\n            bind = torch.from_numpy(train_bind[index]).float().cuda(),\n        )\n\n        net.train()\n        net.output_type = ['loss', 'infer']\n\n        with torch.cuda.amp.autocast(enabled=cfg.is_amp):\n            output = net(batch)  #data_parallel(net,batch) #\n            bce_loss = output['bce_loss']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from multiprocessing import Pool\nfrom tqdm import tqdm\nimport gc\nfrom torch_geometric.loader import DataLoader as PyGDataLoader\n\ndef to_pyg_list(graph):\n\tL = len(graph)\n\tfor i in tqdm(range(L)):\n\t\tN, edge, node_feature, edge_feature = graph[i]\n\t\tgraph[i] = Data(\n\t\t\tidx=i,\n\t\t\tedge_index=torch.from_numpy(edge.T).int(),\n\t\t\tx=torch.from_numpy(node_feature).byte(),\n\t\t\tedge_attr=torch.from_numpy(edge_feature).byte(),\n\t\t)\n\treturn graph\n\n\ntrain_smiles=[ #replace [Dy] with C\n    \"C#CCOc1ccc(CNc2nc(NCc3cccc(Br)n3)nc(N[C@@H](CC#C)CC(=O)NC)n2)cc1\",\n    \"C#CCOc1ccc(CNc2nc(NCc3cccc(Br)n3)nc(N[C@@H](CC#C)CC(=O)NC)n2)cc1\",\n    \"C#CCOc1ccc(CNc2nc(NCc3cccc(Br)n3)nc(N[C@@H](CC#C)CC(=O)NC)n2)cc1\",\n    \"C#CCOc1ccc(CNc2nc(NCc3cccc(Br)n3)nc(N[C@@H](CC#C)CC(=O)NC)n2)cc1\",\n    \"C#CCOc1ccc(CNc2nc(NCc3cccc(Br)n3)nc(N[C@@H](CC#C)CC(=O)NC)n2)cc1\",\n    \"C#CCOc1ccc(CNc2nc(NCc3cccc(Br)n3)nc(N[C@@H](CC#C)CC(=O)NC)n2)cc1\",\n]\ntrain_bind =np.array([\n    [0,0,0],[1,0,0],[0,1,0],[0,0,1],[1,1,0],[0,0,0],\n])\nnum_train= len(train_smiles)\nwith Pool(processes=64) as pool:\n    train_graph = list(tqdm(pool.imap(smile_to_graph, train_smiles), total=num_train))\n\ntrain_graph = to_pyg_list(train_graph)\ntrain_loader = PyGDataLoader(train_graph, batch_size=3, shuffle=True)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## example training loop\nscaler = torch.cuda.amp.GradScaler(enabled=True)\nnet = Net()\nnet.to(DEVICE)\n\noptimizer =\\\n\ttorch.optim.AdamW(filter(lambda p: p.requires_grad, net.parameters()), lr=0.001)\n\nnum_epoch=10\nepoch=0\niteration=0\nwhile epoch<num_epoch: \n\tfor t, graph_batch in enumerate(train_loader): \n\t\tindex = graph_batch.idx.tolist()\n\t\tB = len(index)\n\t\tbatch = dotdict(\n\t\t\tgraph  = graph_batch.to(DEVICE),\n\t\t\tbind   = torch.from_numpy(train_bind[index]).to(DEVICE),\n\t\t)\n\n\t\tnet.train()\n\t\tnet.output_type = ['loss', 'infer']\n\t\twith torch.cuda.amp.autocast(enabled=True):\n\t\t\toutput = net(batch)  #data_parallel(net,batch) #\n\t\t\tbce_loss = output['bce_loss']\n\n\t\toptimizer.zero_grad() \n\t\tscaler.scale(bce_loss).backward() \n\t\tscaler.step(optimizer)\n\t\tscaler.update()\n\t\t \n\t\ttorch.clear_autocast_cache()\n\t\tprint(epoch,iteration,bce_loss.item())\n\t\titeration +=  1\n        \n\tepoch += 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path ='/kaggle/input/leash-BELKA/train.parquet'\n\ncon = duckdb.connect()\ndf_train = con.query(f\"\"\"(SELECT *\n                        FROM parquet_scan('{train_path}')\n                        WHERE binds = 0\n                        ORDER BY random()\n                        LIMIT 30000)\n                        UNION ALL\n                        (SELECT *\n                        FROM parquet_scan('{train_path}')\n                        WHERE binds = 1\n                        ORDER BY random()\n                        LIMIT 30000)\"\"\").df()\ncon.close()\nprint('DONE!')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import Sequential, Linear, ReLU\nfrom torch_geometric.nn import GATConv\nfrom torch_geometric.nn import global_max_pool as gmp\n\n# GAT  model\nclass GATNet(torch.nn.Module):\n    def __init__(self, num_features=112, n_output=1,n_filters=32, embed_dim=128, output_dim=128, dropout=0.2):\n        super(GATNet, self).__init__()\n\n        # graph layers\n        self.gcn1 = GATConv(num_features, num_features, heads=10, dropout=dropout)\n        self.gcn2 = GATConv(num_features * 10, output_dim, dropout=dropout)\n        self.fc_g1 = nn.Linear(output_dim, output_dim)\n\n        # combined layers\n        self.fc1 = nn.Linear(output_dim, 64)\n        self.fc2 = nn.Linear(64, 32)\n        self.out = nn.Linear(32, n_output)\n\n        # activation and regularization\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, data):\n        # graph input feed-forward\n        x, edge_index, batch = data.x.float(), data.edge_index, data.batch\n\n        x = F.dropout(x, p=0.2, training=self.training)\n        x = F.elu(self.gcn1(x, edge_index))\n        x = F.dropout(x, p=0.2, training=self.training)\n        x = self.gcn2(x, edge_index)\n        x = self.relu(x)\n        x = gmp(x, batch)          # global max pooling\n        x = self.fc_g1(x)\n        x = self.relu(x)\n\n       \n        # add some dense layers\n        xc = self.fc1(x)\n        xc = self.relu(xc)\n        xc = self.dropout(xc)\n        xc = self.fc2(xc)\n        xc = self.relu(xc)\n        xc = self.dropout(xc)\n        out = self.out(xc)\n        return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}